<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Wasim Lorgat">
<meta name="dcterms.date" content="2023-02-13">
<meta name="description" content="A step-by-step account of how I built Meepo – a visual search engine for fashion – and how you can create your own search engine too.">

<title>Wasim Lorgat - How I built Meepo: A visual search engine for fashion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="../site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script defer="" data-api="https://meepo.shop/api/event" data-domain="wasimlorgat.com" src="https://meepo.shop/js/script.outbound-links.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<meta property="og:title" content="Wasim Lorgat - How I built Meepo: A visual search engine for fashion">
<meta property="og:description" content="A step-by-step account of how I built Meepo – a visual search engine for fashion – and how you can create your own search engine too.">
<meta property="og:image" content="https://wasimlorgat.com/posts/images/meepo.png">
<meta property="og:site-name" content="Wasim Lorgat">
<meta property="og:image:height" content="900">
<meta property="og:image:width" content="1600">
<meta name="twitter:title" content="Wasim Lorgat - How I built Meepo: A visual search engine for fashion">
<meta name="twitter:description" content="A step-by-step account of how I built Meepo – a visual search engine for fashion – and how you can create your own search engine too.">
<meta name="twitter:image" content="https://wasimlorgat.com/posts/images/meepo.png">
<meta name="twitter:creator" content="@wasimlorgat">
<meta name="twitter:site" content="@wasimlorgat">
<meta name="twitter:image-height" content="900">
<meta name="twitter:image-width" content="1600">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Wasim Lorgat</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../projects.html" rel="" target="">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../tils/index.html" rel="" target="">
 <span class="menu-text">TILs</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/wasimlorgat" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seem" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com/in/wasim-lorgat" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../tils/index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text">TILs</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#contrastive-language-image-pretraining" id="toc-contrastive-language-image-pretraining" class="nav-link active" data-scroll-target="#contrastive-language-image-pretraining">Contrastive language-image pretraining</a></li>
  <li><a href="#build-a-search-engine-for-oxford-pets" id="toc-build-a-search-engine-for-oxford-pets" class="nav-link" data-scroll-target="#build-a-search-engine-for-oxford-pets">Build a search engine for Oxford Pets</a></li>
  <li><a href="#the-idea" id="toc-the-idea" class="nav-link" data-scroll-target="#the-idea">The idea</a></li>
  <li><a href="#notebook-prototype" id="toc-notebook-prototype" class="nav-link" data-scroll-target="#notebook-prototype">Notebook prototype</a></li>
  <li><a href="#web-prototype" id="toc-web-prototype" class="nav-link" data-scroll-target="#web-prototype">Web prototype</a></li>
  <li><a href="#deployment" id="toc-deployment" class="nav-link" data-scroll-target="#deployment">Deployment</a></li>
  <li><a href="#scraper" id="toc-scraper" class="nav-link" data-scroll-target="#scraper">Scraper</a></li>
  <li><a href="#launch" id="toc-launch" class="nav-link" data-scroll-target="#launch">Launch</a></li>
  <li><a href="#image-search" id="toc-image-search" class="nav-link" data-scroll-target="#image-search">Image search</a></li>
  <li><a href="#cost" id="toc-cost" class="nav-link" data-scroll-target="#cost">Cost</a></li>
  <li><a href="#thats-all-folks" id="toc-thats-all-folks" class="nav-link" data-scroll-target="#thats-all-folks">That’s all folks</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">How I built Meepo: A visual search engine for fashion</h1>
  <div class="quarto-categories">
    <div class="quarto-category">maker log</div>
  </div>
  </div>

<div>
  <div class="description">
    A step-by-step account of how I built Meepo – a visual search engine for fashion – and how you can create your own search engine too.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Wasim Lorgat </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 13, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload</code></pre>
</div>
</div>
<!-- ![](images/meepo.png){width=600 fig-align=center .preview-image} -->
<p>I built a visual search engine for a leading fashion store in the Southern-most tip of Africa. Thanks to the power and availability of foundational neural networks, open-source software, and cloud infrastructure – with a sprinkle of good planning – it took me 1 week and costs me only $30 per month to host.</p>
<p>Honestly, it blows my mind that this is possible. Decades of hard work by many bright minds have empowered us to create and distribute incredible AI-powered products from almost anywhere in the world.</p>
<p>I couldn’t be more excited about what this means for our future. What problems will we be able to solve? This is why I decided to share how I built Meepo. I hope to help others create even more powerful products that solve problems unique to their circumstances.</p>
<p>Here’s the entire stack powering Meepo. Don’t be overwhelmed. In this post, you’ll learn about each and every one of these, and how you can use them to create your own search engine:</p>
<ul>
<li><a href="#contrastive-language-image-pretraining">Contrastive language-image pretraining</a>: the deep learning method powering Meepo’s search</li>
<li><a href="https://github.com/facebookresearch/faiss">Faiss</a>: a library that lets us efficiently search over CLIP outputs</li>
<li><a href="https://docs.conda.io/en/latest/">Conda</a>: a Python package management system</li>
<li><a href="https://jupyter.org/">Jupyter Notebook</a>: an interactive programming environment</li>
<li><a href="http://nbdev.fast.ai/">nbdev</a>: a platform for developing software using Jupyter Notebooks</li>
<li><a href="https://tailwindcss.com/">Tailwind CSS</a>: a simpler CSS framework</li>
<li><a href="https://daisyui.com/">DaisyUI</a>: a component library built on Tailwind CSS</li>
<li><a href="https://www.sqlite.org/">SQLite</a>: a light but powerful database engine</li>
<li><a href="https://www.djangoproject.com/">Django</a>: a battle-tested Python web framework</li>
<li><a href="">Gunicorn</a>: a Python HTTP server that lets us serve our Django application</li>
<li><a href="https://www.nginx.com/">Nginx</a>: a powerful and customizeable web server</li>
<li><a href="https://cron.com/">Cron</a>: a job scheduler built into Unix operating system</li>
<li><a href="https://www.linode.com/">Linode</a>: a cloud hosting provider.</li>
</ul>
<section id="contrastive-language-image-pretraining" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="contrastive-language-image-pretraining">Contrastive language-image pretraining</h2>
<p>Contrastive language-image pretraining is the essential building block that makes Meepo possible. The approach was originally proposed by <a href="http://arxiv.org/abs/2010.00747">Zhang et al.&nbsp;(2020)</a> in the medical domain, and termed ConVIRT (Contrastive Visual Representation Learning from Text). OpenAI later demonstrated the true power of the method by scaling up to a 2000x larger dataset.</p>
<p>As with most machine learning innovations, it starts with data. Because high-quality annotations of medical images are expensive to produce, prior work fine-tuned models pretrained on large image datasets like ImageNet. However, medical images are are often drastically different to natural images, and require discriminating between very fine-grained details, which makes ImageNet a poor pretraining target. One workaround is to craft expert rules to extract labels from doctor’s textual reports. While this has produced larger datasets, these rules are not much easier to create than manually annotating, and they don’t generalize well across domains and writing styles.</p>
<p>ConVIRT’s key insight was to instead exploit paired descriptions from doctor’s reports <em>in their natural language format</em>, such as the examples shown below. This not only produces larger datasets at lower cost, but also learns image representations with significantly better transfer to other domains and tasks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/meepo-convirt-examples.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">X-ray images with naturally occurring paired descriptions from doctor’s reports. Source: Figure 1 of Zhang et al., 2020</figcaption><p></p>
</figure>
</div>
<p>The idea is to pretrain a neural network to predict the most relevant text snippet given an image and vice versa. However, we use a <em>contrastive</em> rather than <em>predictive</em> objective.</p>
<p>A predictive object might take the image as input and try to predict label indicating the corresponding text snippet.</p>
<p>On the other hand, a constrative objective would instead predict a vector for each image and another vector for each text snippet; these vectors are called <em>embeddings</em>. It would learn to produce embeddings that maximize the cosine similarity of the correct pair (i.e.&nbsp;the image embedding and its corresponding text embedding) and minimizing that of the remaining pairs (i.e.&nbsp;the image embedding and embeddings of other random text snippets from the dataset).</p>
<div class="page-columns page-full"><p>It turns out that contrastive objectives learn representations that transfer much more efficiently than predictive objectives. For instance, OpenAI found that a contrastive objective reached the same zero-shot ImageNet accuracy<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> as the predictive objective while using 4x fewer training examples.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Zero-shot means that a model was not trained on any examples from a given dataset. In this case, “zero-shot ImageNet accuracy” refers to the accuracy obtained without training on any ImageNet examples.</p></li></div></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/clip-training.png" class="img-fluid figure-img" width="600"></p>
<p></p><figcaption class="figure-caption">A visualization of the contrastive language-image pretraining approach. Source: <a href="https://openai.com/blog/clip/">CLIP: Connecting Text and Images</a> by OpenAI.</figcaption><p></p>
</figure>
</div>
<!-- The simple image retrieval pretraining task results in a neural network with zero-shot capabilities matching supervised approaches on a variety of downstream tasks and datasets. For example, CLIP matches the original ResNet-50 performance on ImageNet without training on any of its 1.28 million training examples. -->
<p>Although the retrieval pretraining task was originally chosen for its ability to learn useful representations for downstream tasks, ConVIRT still achieved state-of-the-art performance at the retrieval task itself. This key finding is what lets us create a simple yet powerful visual search engine like Meepo, given access to a dataset of only images without paired queries.</p>
<div class="page-columns page-full"><p>Despite the fact that the retrieval pretraining task was initially picked for its capacity to learn valuable representations for downstream tasks<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, the ConVIRT model still performed better than any other model at the retrieval task. This crucial discovery is what enables us to create a visual search engine that is both simple and powerful, like Meepo, even with a dataset that only contains images without paired text queries.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;“Downstream tasks” refer to tasks that are performed using the learned representations from a pretrained model. These tasks can include image classification, object detection, and visual search, among others.</p></li></div></div>
<div class="page-columns page-full"><p>Although ConVIRT has shown promise, it was trained on far fewer examples than most modern deep learning models. For instance, ImageNet has around 1.2 million training examples, which is 6000 times more than ConVIRT’s dataset. However, OpenAI’s <a href="https://openai.com/blog/clip/">CLIP</a> has applied a more training-efficient version of ConVIRT to a dataset of 400 million image-text pairs collected from the internet, which is 2000 times more examples than ConVIRT’s original dataset. CLIP achieved state-of-the-art zero-shot ImageNet accuracy as well as zero-shot text-to-image retrieval accuracy on the Flickr30k dataset.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;Fast forward two years and CLIP has been dethroned several times. Most recently, by <a href="http://arxiv.org/abs/2301.12597">BLIP-2</a> which builds on top of frozen off-the-shelf pretrained vision and language models instead of training from scratch.</p></li></div></div>
<p>The CLIP <a href="https://github.com/openai/CLIP">model code and weights</a> are available for anyone to use. This has allowed other innovations, like <a href="https://stability.ai/blog/stable-diffusion-public-release">Stable Diffusion</a>, a state-of-the-art image algorithm, to use it as well. However, the dataset used to train CLIP, called WebImageText, has not been released by OpenAI. Fortunately, the machine learning community has trained the <a href="https://github.com/mlfoundations/open_clip">OpenCLIP</a> model from scratch on public datasets, achieving similar accuracy to CLIP.</p>
<p>Now that we have some background on CLIP and its impressive zero-shot text-to-image retrieval capabilities, how do we actually create a visual search engine like Meepo?</p>
</section>
<section id="build-a-search-engine-for-oxford-pets" class="level2">
<h2 class="anchored" data-anchor-id="build-a-search-engine-for-oxford-pets">Build a search engine for Oxford Pets</h2>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This section is under construction
</div>
</div>
<div class="callout-body-container callout-body">
<p>Check back in a few days.</p>
</div>
</div>
<p>Let’s create a text-to-image search engine for the Oxford Pets dataset.</p>
<p>First install the required libraries. Both of these were created by HuggingFace:</p>
<ul>
<li><a href="https://huggingface.co/docs/datasets/index">Datasets</a> lets us easily access and share datasets for a variety of machine learning tasks</li>
<li><a href="https://huggingface.co/docs/transformers/index">Transformers</a> lets us easily download, train, and use state-of-the-art pretrained neural networks.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>q torch datasets transformers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then load the <a href="https://huggingface.co/datasets/pcuenq/oxford-pets">Oxford Pets</a> dataset – thanks to <a href="https://twitter.com/pcuenq">Pedro Cuenqa</a> for uploading it:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"pcuenq/oxford-pets"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Define a helper function to show smaller thumbnails of an image:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> thumbnail(image, scale<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> image.resize(np.array(image.size)<span class="op">//</span>scale)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here’s an example of a cat:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>cat_row <span class="op">=</span> dataset[<span class="st">'train'</span>][<span class="dv">15</span>]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>cat_image <span class="op">=</span> cat_row[<span class="st">'image'</span>]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>thumbnail(cat_image)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="how-i-built-meepo-a-fashion-search-engine_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>… and here’s an example of a dog:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>dog_row <span class="op">=</span> dataset[<span class="st">'train'</span>][<span class="dv">10</span>]</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>dog_image <span class="op">=</span> dog_row[<span class="st">'image'</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>thumbnail(dog_image)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="how-i-built-meepo-a-fashion-search-engine_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Now that we have a dataset, we can load the CLIP processor and model. The concept of having a separate <em>processor</em> and <em>model</em> is central to the HuggingFace Transformers library, since it allows us to use 174 state-of-the-art models (as of writing this article) with a very similar API.</p>
<p>It might take a minute to download the pretrained weights:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> CLIPProcessor, CLIPModel</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> CLIPProcessor.from_pretrained(<span class="st">"openai/clip-vit-base-patch32"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CLIPModel.from_pretrained(<span class="st">"openai/clip-vit-base-patch32"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>CLIPProcessor</code> prepares the inputs for the model. Given an input input <a href="https://pillow.readthedocs.io/en/stable/">Pillow</a> (the go-to Python imaging library) image, the processor will:</p>
<ol type="1">
<li>Convert the input image into a <a href="https://pytorch.org/">PyTorch</a> tensor</li>
<li>Resize the tensor so that the shortest edge is 224 pixels long</li>
<li>Crop the tensor from center to 224x224</li>
<li>Pad the tensor to 224x224 if it’s smaller</li>
<li>Divide by 255 (so that values are in the range 0 to 1)</li>
<li>Normalize values using the mean and standard deviation calculated from the original CLIP dataset</li>
<li>Swap the dimensions to `(channels, width, height).</li>
</ol>
<p>Thankfully, this is all handled seamlessly by the <code>CLIPProcessor</code>. Let’s create a function to embed an image by first passing it through the processor and then into the model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> embed_image(images):</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(images, <span class="bu">list</span>): images <span class="op">=</span> [images]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> processor(images<span class="op">=</span>images, return_tensors<span class="op">=</span><span class="st">"pt"</span>, padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad(): <span class="cf">return</span> model.get_image_features(<span class="op">**</span>inputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Test that it works:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> embed_image(cat_image)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>embeddings.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([1, 512])</code></pre>
</div>
</div>
<p>You can also pass text to the <code>CLIPProcessor</code>. In that case, the processor will:</p>
<ol type="1">
<li>TODO</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> embed_text(text):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> processor(text<span class="op">=</span>text, return_tensors<span class="op">=</span><span class="st">"pt"</span>, padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad(): <span class="cf">return</span> model.get_text_features(<span class="op">**</span>inputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>img_embs <span class="op">=</span> embed_image([cat_image, dog_image])</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>img_embs.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([2, 512])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>text_emb <span class="op">=</span> embed_text(<span class="st">"cat"</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>text_emb.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([1, 512])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalize(a): <span class="cf">return</span> a <span class="op">/</span> a.norm(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cosine_sim(a, b): <span class="cf">return</span> normalize(a) <span class="op">@</span> normalize(b).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> logits(a, b): <span class="cf">return</span> model.logit_scale.exp() <span class="op">*</span> cosine_sim(a, b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> probs(a, b): <span class="cf">return</span> logits(a, b).softmax(dim<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> is_dog(image):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    image_emb <span class="op">=</span> embed_image(image)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    template <span class="op">=</span> <span class="st">"a photo of a </span><span class="sc">{}</span><span class="st">"</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    text_emb <span class="op">=</span> embed_text([template.<span class="bu">format</span>(o) <span class="cf">for</span> o <span class="kw">in</span> [<span class="st">"dog"</span>, <span class="st">"cat"</span>]])</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> probs(text_emb, image_emb)[<span class="dv">0</span>].item()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>is_dog(cat_image)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>0.005954070948064327</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>is_dog(dog_image)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>0.9972768425941467</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify(image, classes, template<span class="op">=</span><span class="st">"a photo of a </span><span class="sc">{}</span><span class="st">"</span>):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    image_emb <span class="op">=</span> embed_image(image)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    text_emb <span class="op">=</span> embed_text([template.<span class="bu">format</span>(o) <span class="cf">for</span> o <span class="kw">in</span> classes])</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {k: v.item() <span class="cf">for</span> k, v <span class="kw">in</span> <span class="bu">zip</span>(classes, probs(text_emb, image_emb))}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> [<span class="st">"siamese"</span>, <span class="st">"beagle"</span>]</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>classify(cat_image, classes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'siamese': 0.9902162551879883, 'beagle': 0.009783802554011345}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>classify(dog_image, classes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'siamese': 7.44477438274771e-05, 'beagle': 0.9999254941940308}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> [<span class="st">"white"</span>, <span class="st">"pink"</span>, <span class="st">"brown"</span>]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>classify(cat_image, classes, <span class="st">"a photo of a </span><span class="sc">{}</span><span class="st"> animal"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'white': 0.9660211801528931,
 'pink': 0.03326801210641861,
 'brown': 0.0007108623394742608}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> search(images, text):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    image_emb <span class="op">=</span> embed_image(images)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    text_emb <span class="op">=</span> embed_text([text])</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> cosine_sim(image_emb, text_emb).flatten().argsort().flip([<span class="dv">0</span>])</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [images[i] <span class="cf">for</span> i <span class="kw">in</span> indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> search([cat_image, dog_image], <span class="st">"cat"</span>): display(thumbnail(o))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="how-i-built-meepo-a-fashion-search-engine_files/figure-html/cell-26-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="how-i-built-meepo-a-fashion-search-engine_files/figure-html/cell-26-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> search([cat_image, dog_image], <span class="st">"dog"</span>): display(thumbnail(o))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="how-i-built-meepo-a-fashion-search-engine_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="how-i-built-meepo-a-fashion-search-engine_files/figure-html/cell-27-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Loading all images into memory at once would require about 17.2 GB of RAM. So we have to embed them one-by-one. An optimization could be to embed in chunks large enough to fit in memory, but this is simpler!</p>
<p>TODO: Maybe we can upload this as a huggingface dataset?</p>
<p>Let’s embed all of the images. This took 19 minutes on my laptop:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %%time</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co"># embeddings = [embed_image(row['image']) for row in tqdm(dataset['train'])]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># emb = np.concatenate(embeddings)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># np.save("oxford_pets_embeddings.npy", emb)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># emb2 = np.load("oxford_pets_embeddings.npy")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># assert np.allclose(emb, emb2)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_bar(embeddings):</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">2</span>))</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    ax.bar(np.arange(embeddings.shape[<span class="dv">1</span>]), embeddings[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>plot_bar(embed_image(cat_image))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="how-i-built-meepo-a-fashion-search-engine_files/figure-html/cell-36-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>plot_bar(embed_image(dog_image))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="how-i-built-meepo-a-fashion-search-engine_files/figure-html/cell-37-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>That’s one way to visualize embeddings, but they are most useful in the context of other embedded objects.</p>
</section>
<section id="the-idea" class="level2">
<h2 class="anchored" data-anchor-id="the-idea">The idea</h2>
<p>Leading up to Meepo, I’d seen the creator of <a href="https://lexica.art/">Lexica</a> share the <a href="https://twitter.com/sharifshameem/status/1567962701237997568?s=20">details of their stack</a> on Twitter. I’d also recently learned the detail behind how CLIP worked from the <a href="https://www.fast.ai/posts/part2-2022-preview.html">most recent iteration of the incredible fastai course</a>. Shortly after that, I saw <a href="https://twitter.com/karinanguyen_/status/1587217615885406213">the launch</a> of <a href="https://interalia.vcflab.org/">InterAlia</a>. I had a brief look at the tech, and it looked simple enough to be able to very quickly prototype.</p>
<p>I wanted to build this as quickly as possible. And I wanted to do so in a series of incremental steps, each resulting in an end-to-end useable product.</p>
</section>
<section id="notebook-prototype" class="level2">
<h2 class="anchored" data-anchor-id="notebook-prototype">Notebook prototype</h2>
<p>Later that day, I shared the first demo with friends:</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="videos/meepo-demo-1.mp4"></video></div>
<p>In general, I always try to focus on the most uncertain part of the project at each step. At this stage I wasn’t sure if the search would actually work for the types of queries a shopper would have, like “wooden bowl” or “small purple lamp”. So the first step was to isolate and answer that specific question, as quickly as possible.</p>
<p>I manually scraped some images from the target website: literally opened the website and scraped the image URLs with some JavaScript in the browser console. I only scraped one page to start with, which was about 70 images. Then I CLIP encoded the images and did simple distance ranking on those vectors.</p>
<p>This took about 1 hour in total. And it worked quite well!</p>
</section>
<section id="web-prototype" class="level2">
<h2 class="anchored" data-anchor-id="web-prototype">Web prototype</h2>
<p>The next step was to do the same thing in a web app. The simplest approach I could think of was a server-side rendered app that served static pages with a search interface implemented as a standard HTML form.</p>
<p>As for design, I knew that I was going to use an existing component library so that I could have a decent UI without much customization. I really like the way DaisyUI’s components look, and it’s free, so I went with that. I love how it turned out!</p>
<p>I started out by drawing a simple design with pen and paper. Even though this is a pretty basic design, I found it very helpful to draw it out. It gave me a clear goal to work towards. This is also when I decided on the name “Meepo”, which my wife suggested. It’s the name of a <a href="https://dota2.fandom.com/wiki/Meepo">DotA character</a> that she liked, and it felt like the right vibe.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/meepo-sketch.png" class="img-fluid figure-img" width="600"></p>
</figure>
</div>
<p>I used Django as the backend framework since I have a few years of experience with it. Again, since the goal was to ship fast, I tried to go with what I knew: simple, boring, but powerful! I used SQLite too to keep things simple, since it’s almost entirely a read-only application; only the scraper writes to the database.</p>
<p>This step took 4 hours, after which I shared another demo with friends.</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video2" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="videos/meepo-demo-2.mp4"></video></div>
</section>
<section id="deployment" class="level2">
<h2 class="anchored" data-anchor-id="deployment">Deployment</h2>
<p>Now that I had a minimal working Django app, I wanted to deploy it so that I could share a link for people to play around with, instead of just videos. I found it very helpful to get feedback throughout the process, and there’s nothing better than getting feedback on an actual interactive version of the product. I also wanted to get practice shipping changes to a live app. I definitely think it’s the right idea to deploy early in the development process, then ship often.</p>
<p>I used the battle-tested stack of nginx and gunicorn in front of Django (image created by <a href="https://medium.com/@serdarilarslan">Serdar Ilarslan</a>, <a href="https://medium.com/@serdarilarslan/what-is-gunicorn-5e674fff131b">source</a>):</p>
<p><img src="images/meepo-stack.webp" class="img-fluid"></p>
<p>This step took 7 hours. I think it could’ve been a lot faster, but I got sidetracked trying to use a platform-as-a-service (PaaS) option instead of working directly on a Linux virtual private server (VPS) – which I’m much more experienced with. I’m not sure if I’ll revisit PaaS in the future, because the VPS has been working really well for a few months now. I personally love the transparency and being able to directly interact with it if anything goes wrong, rather than struggling to find the right logs in some web interface. I knew that <a href="https://twitter.com/levelsio">Pieter Levels</a> does similarly, and serves significantly more traffic than I expected to. My good friend <a href="https://twitter.com/ashtonshudson">Ashton Hudson</a> took the same approach with <a href="https://www.servaltracker.com/">Serval</a>, which also serves tons of traffic with a really massive time series database (more info in <a href="https://twitter.com/ashtonshudson/status/1609621491481460737?s=20">this thread</a>).</p>
<p>I bought a DNS using Namecheap. I tried to find the cheapest domain for “meepo”, and was lucky to score <a href="https://meepo.shop">meepo.shop</a> at $2!</p>
<p>I did some basic Linux setup following <a href="https://www.linode.com/docs/products/compute/compute-instances/guides/set-up-and-secure/">this Linode guide</a>. Things like updating packages, configuring the timezone, configuring a custom hostname, and most importantly creating a limited user and tightening SSH options.</p>
<p>I found the docs really difficult to follow, but it turned out to be quite simple to get Linode to manage the DNS instead of Namecheap. All I had to do was go to the domain management page, then the Domain tab, and add Linode’s nameservers under the Nameservers section. The domains were ns1.linode.com through ns5.linode.com. I think it might’ve taken some time to reflect, and once it did, I could create a domain in the Linode console, link it to my Node, and have it automatically fill what I needed!</p>
<p>As part of this step, I also setup nginx and gunicorn on the Linux VPS. I followed <a href="https://realpython.com/django-nginx-gunicorn">this Real Python guide</a>.</p>
<p>I also highly recommend setting up Longview, which has a free option! It’s really cool to be able to check some basic stats from the console and even from my phone.</p>
<p>I also setup <a href="https://sentry.io/">Sentry</a> which sends me an email whenever there’s an error in either the web server or the scraper, with a neat stacktrace and local variables. It’s very easy with Django, just a few lines in your <code>settings.py</code> file and you’re good to go.</p>
<p>Once it was setup, I used <a href="https://github.com/ddosify/ddosify">ddosify</a> to load test it – great tool! Given that I’d barely done any optimization, I wanted to make sure that it could at least handle a reasonable amount of traffic. So I hit the search endpoint with a bunch of random queries. It just about handled 60 requests over 10 seconds, which I was relatively sure I wouldn’t reach for an extended period of time 😅 and worst case I could upgrade the VPS if needed.</p>
<p><img src="images/meepo-ddosify.png" class="img-fluid"></p>
<p>Now I could tell people to goto <a href="https://meepo.shop">meepo.shop</a> and see what I was working on. Yay! 🎉</p>
</section>
<section id="scraper" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="scraper">Scraper</h2>
<p>The next step was to come up with a scraping strategy and pipeline design. This was probably the trickiest, but fortunately this sort of work has been a large part of my role as an ML Engineer 💪🏽.</p>
<p>The big question here is how do we maintain a list of available products that is accurate for at least 24 hours, with minimal load to the upstream service?</p>
<p><strong>A very important detour:</strong> if you’re scraping, you are most likely not the intended audience of a website, so try very hard not to negatively impact the service or the user experience of their intended audience! Here are some ways you can do so:</p>
<ul>
<li>Check how big the viewership of the website is. I would personally be hesitant to scrape a small website and would probably prefer to email the owner directly.</li>
<li>Identify yourself (website URL), with contact information, via the user agent header – don’t try to fake being a human! A simple pattern you can use is&nbsp;<code>your.website.com/x.y (your@email.com)</code>&nbsp;where&nbsp;<code>x.y</code>&nbsp;is a version number of the scraper.</li>
<li>Be considerate about their resource usage, especially given that you aren’t their intended audience.</li>
<li>Do the bulk of your requests during off-peak times depending on the local timezone of their audience.</li>
<li>Sleep between requests as much as you possibly can. Add small random amounts as well to reduce the likelihood of overlapping with other scheduled scrapers/bots, thus reducing peak load.</li>
<li>Use compression when scraping plain text or JSON to minimise their outgoing traffic! It doesn’t work nearly as well for images so it’s probably best to not compress them to avoid extra CPU usage on their servers.</li>
</ul>
<p>The rough idea was to:</p>
<ol type="1">
<li>First scrape the entire “catalogue”. Walk through each department’s “New in” section</li>
<li>Then for each page in the section, create a list of the currently available products.</li>
<li>Download the images for those products that we haven’t seen before.</li>
<li>Calculate their CLIP embeddings</li>
<li>And finally rebuild the index.</li>
</ol>
<p>It’s faster for me to recreate the index instead of updating the existing one due to the small size of my dataset. For larger datasets this would be a more complex process.</p>
<p>Unfortunately, I couldn’t scrape new pages only. I needed to check the entire catalogue to determine which products were unavailable so I can remove them from the index.</p>
<p>I first tried jumping in head first and coding this up, but got totally stuck. Even with that plan I wasn’t quite sure how to break it down into smaller components that I could easily build.</p>
<p>A perfect opportunity to whip out a whiteboard, or in my case <a href="https://excalidraw.com">Excalidraw</a>. Here’s what I came up with:</p>
<p class="page-columns page-full"><img src="images/meepo-pipeline.png" class="column-screen img-fluid"></p>
<p>I often find it helpful to think about data pipelines in terms of statements that I want to be true about the data.</p>
<p>For example, after step 1, we should have a .json.gz file for each scraped page, in a folder structure indicating the run timestamp, department, and page number. It’s also useful to specify a more precise schema at this point too. What would the file structure look like? What tables will you create in the database, and what are their constraints and foreign key relationships?</p>
<p>It’s also often a good idea to store raw external data before we do any processing so that when we change the logic we don’t need to rescrape anything. For example, if I wanted to add prices to products I could do so without rescraping anything. This is also one good reason for splitting a pipeline into smaller components. Another is that it can be easier to comprehend, although splitting it too fine can be counterproductive.</p>
<p>I used Chrome dev tools to figure out the API paths and what the requests should look like. Although I built the scraper to work with all departments, I started out by scraping the smallest one: Home and Living. I figured that would be a neat way to test the end-to-end process.</p>
<p>I then configured cron to run this daily just after midnight. By the way, a neat tip to get cron to log its output (including errors) to the system log is to add the following to the end of your job definition:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="op">&gt;&amp;</span><span class="dv">1</span> <span class="kw">|</span> <span class="ex">logger</span> <span class="at">-t</span> meepo_pipeline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>2&gt;&amp;1</code> redirects the standard error stream to the standard out stream so that error messages are logged too. The combined result is then piped to the <code>logger</code> application which writes to the system log, with a tag specified by the <code>-t</code> flag.</p>
<p>Building out the scraper and getting the cron job working smoothly took about 20 hours! After that, all that was left was to let it scrape all departments, watch and fix any bugs that popped up (unhandled cases and so on), and prepare for launch!</p>
</section>
<section id="launch" class="level2">
<h2 class="anchored" data-anchor-id="launch">Launch</h2>
<p>My launch plan was simple. Post to Twitter, LinkedIn, Reddit (/r/southafrica), and HackerNews:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Introducing Meepo – a smarter search engine for <a href="https://twitter.com/superbalist?ref_src=twsrc%5Etfw"><span class="citation" data-cites="Superbalist">@Superbalist</span></a> (leading South African fashion and homeware store 🇿🇦)<br><br>I have no affiliation with Superbalist. I just thought this was something that needed to exist! Let me explain…<a href="https://t.co/5HNOfM6k1T">https://t.co/5HNOfM6k1T</a>
</p>
— Wasim Lorgat (<span class="citation" data-cites="wasimlorgat">@wasimlorgat</span>) <a href="https://twitter.com/wasimlorgat/status/1596038255236915200?ref_src=twsrc%5Etfw">November 25, 2022</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>There are a couple of tiny details that really add to the polish of a launch: having a nice social preview card (and other metadata) and a favicon.</p>
<p>For the preview card, I used <a href="https://unsplash.com/">Unsplash</a> to find a beautiful stock photo, and then <a href="https://www.canva.com/">Canva</a> to edit it. Be sure to get the dimensions right for the website(s) you’re targeting. For me it was primarily Twitter and Reddit. I cropped the image, played around with colour settings, added text, and added some pretty fonts and effects. I was inspired by Lexica’s card which I think is really beautiful. I added a headline and short description over the image.</p>
<p>For favicons, my goto is a simple 1 or 2 letters with a nice font in the same colour scheme as the website. I used <a href="https://favicon.io/">favicon.io</a> to create mine. You can use emojis too, which I might consider in the future.</p>
<p>Here’s the stock image I used, credit to <a href="https://unsplash.com/@harpersunday">Harper Sunday</a> (<a href="https://unsplash.com/photos/RmQWqLKsVv8">source</a>):</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/meepo-stock.avif" class="img-fluid figure-img" width="400"></p>
</figure>
</div>
<p>At some point I’d like to start working with a designer for these sorts of things. Let me know if you’re interested!</p>
<p>This step took about 4 hours total.</p>
</section>
<section id="image-search" class="level2">
<h2 class="anchored" data-anchor-id="image-search">Image search</h2>
<p>Thanks to the power of CLIP, it was really easy to add image search after launching the site.</p>
<p>Here’s how it works. I try to parse the search query, and if it’s a URL of an image (and the image isn’t larger than some file limit), I download the image (in-memory, I don’t wanna store arbitrary files), calculate its CLIP embedding, and use that to find similar images.</p>
<p>One possible improvement is to use the average of the image embedding and the text embedding as the query, which I suspect is closer to what users expect from the feature. For example, a user might take an average of the image and the existing text query, which is closer to what I think people would expect.</p>
<p>This took 2 hours to implement end-to-end.</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video3" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="videos/meepo-demo-3.mp4"></video></div>
</section>
<section id="cost" class="level2">
<h2 class="anchored" data-anchor-id="cost">Cost</h2>
<p>The biggest cost here was really the ~40 hours it took to build. Other than that, Meepo cost me $30/month via Linode. The bottleneck is RAM. I need a 4GB server, which adds a fair bit to the cost, though I definitely could’ve reduced that by playing around with something like <a href="https://github.com/criteo/autofaiss">autofaiss</a>.</p>
</section>
<section id="thats-all-folks" class="level2">
<h2 class="anchored" data-anchor-id="thats-all-folks">That’s all folks</h2>
<p>All-in-all, I had tons of fun working on Meepo!</p>
<p>If you found this helpful or entertaining, please do follow me on Twitter <a href="https://twitter.com/wasimlorgat"><span class="citation" data-cites="wasimlorgat">@wasimlorgat</span></a>. And if you have any feedback, comments or questions, please feel free to pop me <a href="mailto:mwlorgat@gmail.com">an email</a>.</p>
<p>I’m now building my own native macOS Jupyter frontend. If that sounds interesting, the best place to follow along is via Twitter.</p>
<p>Take care 👋🏽.</p>


</section>


</main> <!-- /main -->
<script>
  let links = document.querySelectorAll("a[data-analytics]");
  for (var i = 0; i < links.length; i++) {
      links[i].addEventListener('click', handleLinkEvent);
      links[i].addEventListener('auxclick', handleLinkEvent);
  }

  function handleLinkEvent(event) {
      var link = event.target;
      var middle = event.type == "auxclick" && event.which == 2;
      var click = event.type == "click";
      while (link && (typeof link.tagName == 'undefined' || link.tagName.toLowerCase() != 'a' || !link.href)) {
          link = link.parentNode;
      }
      if (middle || click) {
          let attributes = link.getAttribute('data-analytics').split(/,(.+)/);
          let events = [JSON.parse(attributes[0]), JSON.parse(attributes[1] || '{}')];
          plausible(...events);
      }
      if (!link.target) {
          if (!(event.ctrlKey || event.metaKey || event.shiftKey) && click) {
              setTimeout(function () {
                  location.href = link.href;
              }, 150);
              event.preventDefault();
          }
      }
  }
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="seem/blog" data-repo-id="R_kgDOIBWk3A" data-category="Announcements" data-category-id="DIC_kwDOIBWk3M4CSSa6" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
</div> <!-- /content -->
<script>videojs(video_shortcode_videojs_video1);</script>
<script>videojs(video_shortcode_videojs_video2);</script>
<script>videojs(video_shortcode_videojs_video3);</script>



</body></html>