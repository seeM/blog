[
  {
    "objectID": "tils/how-to-share-terminal-demos-as-razor-sharp-animated-svg.html",
    "href": "tils/how-to-share-terminal-demos-as-razor-sharp-animated-svg.html",
    "title": "How to share terminal demos as razor-sharp animated SVG",
    "section": "",
    "text": "Install asciinema and svg-term-cli.\nRecord with asciinema:\nasciinema rec demo.cast\nThis records the session in the asciicast v2 plaintext file format (newline-delimited JSON with an initial header object followed by a timestamped event stream of stdin and stdout).\nConvert the .cast file to .svg with svg-term-cli:\nsvg-term --in demo.cast --out demo.svg --window --width 80 --height 22 --no-optimize\n\nYou probably want to play around with width and height\nwindow adds a fake OS window around the terminal session\nI found that no-optimize fixed some weird font rendering issues on my macOS ‚Äì not sure why\n\n\n\nHere‚Äôs an example I created for my blog post Build a text editor with Python and curses:"
  },
  {
    "objectID": "tils/callbacks-vs-async-await.html",
    "href": "tils/callbacks-vs-async-await.html",
    "title": "Callbacks vs async/await",
    "section": "",
    "text": "import ipywidgets\nimport time\nfrom threading import Thread\n\nLet‚Äôs start with a very simple interface. An input text, a submit button, and an output text (disabled=True so that it‚Äôs not editable):\n\ninput_ = ipywidgets.Text(\"Hey ChatGPT, please summarise this text.\")\nbutton = ipywidgets.Button(description=\"Submit\")\noutput = ipywidgets.Text(disabled=True)\ndisplay(input_, button, output)\n\n\n\n\n\n\n\n\n\n\nThis won‚Äôt do anything yet. We need to setup an on_click callback first. We‚Äôll fake a request to OpenAI that simply sleeps for half a second then returns a fixed string. Then we‚Äôll update the output text‚Äôs value with the result:\n\ndef request_open_ai(prompt):\n    time.sleep(0.5)\n    return \"Here's a summary of your text.\"\n\n\ndef update_output(text):\n    output.value = text\n\n\ndef on_click(button):\n    text = request_open_ai(input_.value)\n    update_output(text)\n\n\nbutton.on_click(on_click)\n\nIf you click ‚ÄúSubmit‚Äù now, it should populate the output after half a second.\nIf we do this synchronously and in the main thread, the entire UI will hang during the requestOpenAi call. So instead, we can separate that call into another thread. I think ipywidgets already does a version of this for us. But if it didn‚Äôt, here‚Äôs a very rough version of how we‚Äôd do it:\n\nThread(target=request_open_ai, args=(input,)).run()\n\nBut then how do we get the result and update the output with it? It‚Äôs often trickier to pass data across threads. Instead, we define our request function so that it accepts a callback that gets called with the result:\n\ndef request_open_ai(prompt, on_completion):\n    time.sleep(0.5)\n    on_completion(\"Here's a summary of your text.\")\n\n\ndef on_click(button):\n    Thread(target=request_open_ai, args=(input, update_output)).run()\n\n\ninput_ = ipywidgets.Text(\"Hey ChatGPT, please summarise this text.\")\nbutton = ipywidgets.Button(description=\"Submit\")\noutput = ipywidgets.Text(disabled=True)\nbutton.on_click(on_click)\ndisplay(input_, button, output)\n\n\n\n\n\n\n\n\n\n\nThis works okay, but starts to get very confusing as you add more and more nested callbacks. In fact, it can get so bad that it‚Äôs been nicknamed callback hell. Someone was so frustrated with it that they even created a website! This is where async/await becomes useful, since it looks a lot more like ordinary programming:\n\nimport asyncio\n\n\nasync def request_open_ai(prompt):\n    time.sleep(0.5)\n    return \"Here's a summary of your text.\"\n\n\nasync def on_click(button):\n    text = await request_open_ai(input_.value)\n    update_output(text)\n\nNote how these functions look a lot similar to the original synchronous ones instead of having the weird callbacks.\nIn most UI frameworks, we‚Äôd be able to pass in an async function like the new on_click. I‚Äôm not sure how to do that with ipywidgets, so we need to define a little wrapper that synchronously calls the async function, so we can set it as the button‚Äôs on_click handler (confusing, I know):\n\ndef on_click_sync(button):\n    coroutine = on_click(button)\n    asyncio.ensure_future(coroutine)\n\n\ninput_ = ipywidgets.Text(\"Hey ChatGPT, please summarise this text.\")\nbutton = ipywidgets.Button(description=\"Submit\")\noutput = ipywidgets.Text(disabled=True)\nbutton.on_click(on_click_sync)\ndisplay(input_, button, output)"
  },
  {
    "objectID": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html",
    "href": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html",
    "title": "How to setup a GPU notebook server on Google Cloud Platform (GCP)",
    "section": "",
    "text": "GCP is my current preferred cloud provider for GPU servers. I compared prices last year and found that GCP was the cheapest for lower-end GPUs. The notebook servers offered Vertex AI are very easy to setup. They come with PyTorch and NVIDIA/CUDA drivers already configured. I also prefer options that give me full control over the instance via an SSH connection from my terminal, which this does.\nDepending on when you‚Äôre reading this, these instructions may no longer be valid. Please let me know if that‚Äôs the case!"
  },
  {
    "objectID": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html#setup-a-gcp-account",
    "href": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html#setup-a-gcp-account",
    "title": "How to setup a GPU notebook server on Google Cloud Platform (GCP)",
    "section": "Setup a GCP account",
    "text": "Setup a GCP account\n\nCreate a GCP account here.\nRequest a GPU quota increase (follow the official instructions). This may take up to 48 hours.\nEnable the AI Platform via the left sidebar."
  },
  {
    "objectID": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html#create-a-notebook-instance-using-vertex-ai",
    "href": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html#create-a-notebook-instance-using-vertex-ai",
    "title": "How to setup a GPU notebook server on Google Cloud Platform (GCP)",
    "section": "Create a notebook instance using Vertex AI",
    "text": "Create a notebook instance using Vertex AI\n\nOpen the Vertex AI Workbench.\nClick New Notebook, PyTorch 1.12, then With 1 NVIDIA T4.\nSet your Notebook name.\nChoose a Region and Zone. I went with us-central1 and us-central-1b (which was the cheapest available at the time). Note that your choice of region and zone may affect GPU availability and does slightly affect pricing.\nBy default, you‚Äôll be provided with an n1-standard-4 which has 4 vCPUs and 15 GB RAM, and an NVIDIA Tesla T4. If you need more resources, click the edit button next to Notebook properties, then Machine configuration, set your Machine type and GPU type, then click Create.\nCheck Install NVIDIA GPU driver automatically for me.\nWait a few seconds for the notebook server to spin up. Then click OPEN JUPYTERLAB.\n\n\n\n\n\n\n\nShutdown your server when you‚Äôre done working\n\n\n\nYou‚Äôll be billed for as long as the server is running. You may also be billed a smaller amount for persistent storage even while the server is shutdown."
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html",
    "href": "tils/setting-up-tils-in-pelican.html",
    "title": "Setting up TILs in Pelican",
    "section": "",
    "text": "Inspired by Simon Willison, I started writing TILs (today I learned). I find it incredibly helpful to write as I code, but most of that writing has never left my private notebooks. TILs are my attempt at documenting and sharing my day-to-day learnings in case they might help others. The focus on learning also feels less daunting than writing blog posts.\nI wanted to support TILs on my blog as a separate set of posts with their own listing page. Thanks to Pelican‚Äôs incredible flexibility, this was quite easy!\nFollowing these steps requires using a custom theme. I personally use a custom theme (forked from the builtin simple theme) precisely so that I can easily make these sorts of customisations."
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html#reconfigure-your-archives",
    "href": "tils/setting-up-tils-in-pelican.html#reconfigure-your-archives",
    "title": "Setting up TILs in Pelican",
    "section": "Reconfigure your archives",
    "text": "Reconfigure your archives\nStart by renaming archives.html to posts/index.html (relative to your theme‚Äôs templates directory).\nEdit the loop over dates in posts/index.html to exclude articles tagged til:\n{% for article in dates if 'til' not in article.tags|default([]) %}\nAdd the new path to DIRECT_TEMPLATES, the corresponding line of my pelicanconf.py now looks like:\nDIRECT_TEMPLATES = ['index', 'posts/index']\n‚Ä¶ because I don‚Äôt have tag or category pages yet. Disable the original archives page:\nARCHIVES_SAVE_AS = ''\nIt should be working as it was before, but we‚Äôre now able to add a few more listings in the same way!"
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html#create-the-tils-listing",
    "href": "tils/setting-up-tils-in-pelican.html#create-the-tils-listing",
    "title": "Setting up TILs in Pelican",
    "section": "Create the TILs listing",
    "text": "Create the TILs listing\nCopy posts/index.html to tils/index.html, and edit the for loop to only include articles tagged til (note that the not from before is missing):\n{% for article in dates if 'til' in article.tags|default([]) %}\nAdd the new path to DIRECT_TEMPLATES in your pelicanconf.py:\nDIRECT_TEMPLATES = ['index', 'posts/index', 'tils/index']\nYou probably also want to link to the listing from your nav bar. For my theme, that‚Äôs done by adding a line to the &lt;nav&gt; tag in my base.html template:\n&lt;a href=\"{{ SITEURL }}/tils/\"&gt;TILs&lt;/a&gt;"
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html#hack-article-urls",
    "href": "tils/setting-up-tils-in-pelican.html#hack-article-urls",
    "title": "Setting up TILs in Pelican",
    "section": "Hack article URLs",
    "text": "Hack article URLs\nThis is my favourite part! At this point, you should have two working listings, but TIL article URLs will be the same as any other article. Pelican determines the URL and output location of an article by calling format with the article‚Äôs metadata on strings ARTICLE_URL and ARTICLE_SAVE_AS. That means we can implement a tiny string class with a custom format to dynamically set the URL of TILs to tils/{slug} and of posts to posts/{slug}!\nSimply include the following in your pelicanconf.py:\nclass ArticleUrl(str):\n    def format(self,tags=[],**kwargs): return ('tils/' if 'til' in tags else 'posts/') + super().format(**kwargs)\n\nARTICLE_URL = ArticleUrl('{slug}/')\nARTICLE_SAVE_AS = ArticleUrl('{slug}/index.html')"
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html#update-invoke-task",
    "href": "tils/setting-up-tils-in-pelican.html#update-invoke-task",
    "title": "Setting up TILs in Pelican",
    "section": "Update invoke task",
    "text": "Update invoke task\nIf you‚Äôre using live reload via the invoke livereload task, you‚Äôll need to update your task definition to include nested HTML files in your theme:\n-    server.watch('{}/templates/*.html'.format(theme_path), lambda: build(c))\n+    server.watch('{}/templates/**/*.html'.format(theme_path), lambda: build(c))"
  },
  {
    "objectID": "tils/compiling-python-to-c-using-setuptools-and-cython.html",
    "href": "tils/compiling-python-to-c-using-setuptools-and-cython.html",
    "title": "Compiling Python to C using setuptools and Cython",
    "section": "",
    "text": "plum1 compiles an ordinary Python file into an extension module (in C) using Cython and setuptools‚Äô Cython integration. It‚Äôs the first time I‚Äôve encountered this, so here‚Äôs a high-level description of how it works.\nIn setup.py, pass the ext_modules arg to setup, wrapping an Extension that points to the module you want to compile:\n```python hl_lines=‚Äò9‚Äô from setuptools import setup, Extension\nsetup( # ‚Ä¶ ext_modules=[Extension(‚Äúplum.function‚Äù, [‚Äúplum/function.py‚Äù])], )"
  },
  {
    "objectID": "tils/compiling-python-to-c-using-setuptools-and-cython.html#whats-a-python-extension-module",
    "href": "tils/compiling-python-to-c-using-setuptools-and-cython.html#whats-a-python-extension-module",
    "title": "Compiling Python to C using setuptools and Cython",
    "section": "What‚Äôs a Python extension module?",
    "text": "What‚Äôs a Python extension module?\nAn extension module is a program written in C (or C++) that uses Python‚Äôs C API to hook into Python‚Äôs run-time system. Interop works both ways: you can call Python objects from C and vice versa. A common reason for using extensions is improved speed. See the official docs on extension modules for more."
  },
  {
    "objectID": "tils/compiling-python-to-c-using-setuptools-and-cython.html#whats-cython",
    "href": "tils/compiling-python-to-c-using-setuptools-and-cython.html#whats-cython",
    "title": "Compiling Python to C using setuptools and Cython",
    "section": "What‚Äôs Cython?",
    "text": "What‚Äôs Cython?\nCython is a compiler for compiling programs written in Python and the Cython programming language into C extension modules. I‚Äôd recommend the reading through the rather friendly documentation as well."
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html",
    "href": "tils/using-pelican-as-a-library.html",
    "title": "Using Pelican as a library",
    "section": "",
    "text": "In this post you‚Äôll learn how to use Pelican (a Python static site generator) programmatically rather than through its command-line interface. This will give you a better understanding of how Pelican works internally and enable you to customise it for your needs."
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html#how-pelican-works",
    "href": "tils/using-pelican-as-a-library.html#how-pelican-works",
    "title": "Using Pelican as a library",
    "section": "How Pelican works",
    "text": "How Pelican works\nPelican‚Äôs highest-level of abstraction is its command-line interface, which you would typically use as follows:\n$ pelican content output -s pelicanconf.py\nThis would read all articles and pages in the content directory, convert them to HTML, render web pages with the relevant Jinja templates, and write the resulting static website to the output directory.\nThe rough flow to achieve this is as follows:\n\nInstantiate a list of Generators (which house all of the relevent Readers and a jinja Environment) and a Writer.\nFor each Generator:\n\nCall the generate_context method, which reads the input files, converts them to HTML, and adds the outputs to a context dictionary.\nCall the generate_output method, passing the Writer and context. This gets the relevant jinja Template from the Environment, renders it with the provided context, and writes the result to the final output directory.\n\n\nAs you can see, Generators are responsible for glueing together the lower-level components: Reader, jinja Template, and Writer. In order to understand each of these components, we‚Äôll reimplement the core logic of a Generator from scratch!"
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html#setup",
    "href": "tils/using-pelican-as-a-library.html#setup",
    "title": "Using Pelican as a library",
    "section": "Setup",
    "text": "Setup\nStart by setting root to the directory of your Pelican website. If you don‚Äôt yet have a website, follow Pelican‚Äôs informative documentation to get started:\n\nfrom pathlib import Path\n\nroot = Path('..')\n\nNow we can load our pelicanconf.py settings file. Pelican provides a function for this which handles details like applying defaults:\n\nfrom pelican.settings import read_settings\n\nsettings = read_settings(root/'pelicanconf.py')\n\nLet‚Äôs create a quick blog post for testing. I prefer to write more technical blog posts in Jupyter notebooks but we‚Äôll use markdown here since Pelican supports it natively.\n\npost_filepath = root/'content/2022-06-20-hello-pelican.md'\n\n\n%%writefile {post_filepath}\nTitle: Hello Pelican\nSlug: hello-pelican\nAuthor: Wasim Lorgat\nDate: 2022-06-20\nTags: python, pelican\nCategory: python\n\n## Welcome\n\nHello and welcome to our markdown blog post!\n\nWriting ../content/2022-06-20-hello-pelican.md"
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html#reader",
    "href": "tils/using-pelican-as-a-library.html#reader",
    "title": "Using Pelican as a library",
    "section": "Reader",
    "text": "Reader\nWe‚Äôll start by instantiating a MarkdownReader to read our blog post. We‚Äôre using a MarkdownReader because we wrote the post in markdown, but Pelican also provides HTMLReader and RstReader if you prefer those formats.\n\nfrom pelican.readers import MarkdownReader\n\nreader = MarkdownReader(settings)\n\nThe most important part of a Reader is its read method which accepts a file path and returns the contents of the file in HTML format along with metadata about the file:\n\ncontent, metadata = reader.read(post_filepath)\n\n‚Ä¶ content is a string containing the blog post content converted to HTML. Since this was written in a notebook, we can use an IPython function to render it directly!\n\nfrom IPython.core.display import HTML\nHTML(content)\n\nWelcome\nHello and welcome to our markdown blog post!\n\n\n‚Ä¶ and metadata is a dictionary that describes the file:\n\nmetadata\n\n{'title': 'Hello Pelican',\n 'slug': 'hello-pelican',\n 'author': &lt;Author 'Wasim Lorgat'&gt;,\n 'date': SafeDatetime(2022, 6, 20, 0, 0),\n 'tags': [&lt;Tag 'python'&gt;, &lt;Tag 'pelican'&gt;],\n 'category': &lt;Category 'python'&gt;}"
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html#writer",
    "href": "tils/using-pelican-as-a-library.html#writer",
    "title": "Using Pelican as a library",
    "section": "Writer",
    "text": "Writer\nNow that we have the contents of the post in HTML format, we‚Äôll render it into a static web page using a Writer. However, we first need to create an appropriate jinja Template. Jinja provides the Environment class for reusing functionality across templates so we‚Äôll use that here.\nPelican searches for templates in the following order:\n\nIndividual template overrides, via settings['THEME_TEMPLATES_OVERRIDES'].\nThe configured theme, via settings['THEME'].\nThe default simple theme packaged with Pelican.\n\nWe can implement this search order using a FileSystemLoader, housed in an Environment for convenience:\n\nimport pelican\nfrom jinja2 import Environment, FileSystemLoader\nfrom pathlib import Path\n\ntemplate_paths = [*(Path(o) for o in settings['THEME_TEMPLATES_OVERRIDES']),\n                  Path(settings['THEME'])/'templates',\n                  Path(pelican.__file__).parent/'themes/simple/templates']\nenv = Environment(loader=FileSystemLoader(template_paths),\n                  **settings['JINJA_ENVIRONMENT'])\n\nNow we can get the article template:\n\ntemplate = env.get_template('article.html')\n\nThe last step of preparation is to create the context dictionary that‚Äôs passed through to the Template to render the article:\n\nfrom pelican.contents import Article\n\ncontext = settings.copy()\narticle = Article(content, metadata, settings, post_filepath, context)\narticle.readtime = {'minutes': 1}  # NOTE: this is a workaround to support the readtime plugin that I use\ncontext['article'] = article\n\nAnd now we can write the final result!\n\nfrom pelican.writers import Writer\n\noutput_dir = root/'test'\nwriter = Writer(output_dir, settings)\nwriter.write_file(Path(post_filepath.name).with_suffix('.html'), template, context)\n\nLet‚Äôs read it back in and see what it looks like. We‚Äôll extract only the body using a simple regex - I‚Äôd usually recommend considering Beautiful Soup for parsing HTML but regex works fine for our case:\n\nimport re\n\nwith open(output_dir/'2022-06-20-hello-pelican.html') as f: html = f.read()\nbody = re.findall('&lt;body&gt;(.*?)&lt;/body&gt;', html, re.DOTALL)[0].strip()\nHTML(body)\n\n\n      \n        Wasim Lorgat\n      \n      Posts\n      TILs\n    \n\n\n\n  \n    Hello Pelican\n  \n\n\n\n  June 20, 2022 ‚Ä¢ 1 min read\n\n\nWelcome\nHello and welcome to our markdown blog post!\n\n\nThe provided templates have added a navigation bar at the top, a title below that, as well as the publication date and estimated reading time. And that‚Äôs it, we‚Äôve successfully rendered a blog post web page using Pelican‚Äôs low-level components!\nBefore we end off, clean up the files we made along the way:\n\nimport shutil\nshutil.rmtree(output_dir, ignore_errors=True)\npost_filepath.unlink(missing_ok=True)"
  },
  {
    "objectID": "tils/index.html",
    "href": "tils/index.html",
    "title": "TILs",
    "section": "",
    "text": "I find it incredibly helpful to write as I code, but most of that writing has never left my private notebooks. TILs (today I learneds) are my attempt at documenting and sharing my day-to-day learnings in case they might help others. The focus on learning also feels less daunting than writing blog posts.\n\n\n\n\n\n\n\n\n\n\nUsing shot-scraper to automate screenshots for my writing\n\n\n\n\n\n\n\n\n\n\n\n\n2023-05-22\n\n\n\n\n\n\n\n\nHow to create your own AI avatar using HuggingFace Diffusers and Dreambooth\n\n\n\n\n\n\n\nartificial intelligence\n\n\n\n\n\n\n\n\n\n\n\n2023-03-06\n\n\n\n\n\n\n\n\nCallbacks vs async/await\n\n\n\n\n\n\n\n\n\n\nA quick demonstration of callbacks vs async/await\n\n\n\n\n\n\n2023-02-13\n\n\n\n\n\n\n\n\nHow to use NSTableView in SwiftUI\n\n\n\n\n\n\n\nswift\n\n\n\n\n\n\n\n\n\n\n\n2023-01-25\n\n\n\n\n\n\n\n\nHow to setup a GPU notebook server on Google Cloud Platform (GCP)\n\n\n\n\n\n\n\nartificial intelligence\n\n\n\n\n\n\n\n\n\n\n\n2023-01-23\n\n\n\n\n\n\n\n\nHow to share terminal demos as razor-sharp animated SVG\n\n\n\n\n\n\n\nterminal\n\n\n\n\n\n\n\n\n\n\n\n2022-12-15\n\n\n\n\n\n\n\n\nDiagnosing an issue with plugin modules, process pools, and the import system\n\n\n\n\n\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\n2022-07-10\n\n\n\n\n\n\n\n\nUpdate fastai union annotations using ast\n\n\n\n\n\n\n\nnotebooks\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\n2022-07-08\n\n\n\n\n\n\n\n\nCompiling Python to C using setuptools and Cython\n\n\n\n\n\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\n2022-07-04\n\n\n\n\n\n\n\n\nCreating a minimal custom Jupyter widget\n\n\n\n\n\n\n\nnotebooks\n\n\n\n\n\n\n\n\n\n\n\n2022-06-23\n\n\n\n\n\n\n\n\nPoint and click directory navigation inside a Jupyter notebook\n\n\n\n\n\n\n\nnotebooks\n\n\n\n\n\n\n\n\n\n\n\n2022-06-23\n\n\n\n\n\n\n\n\nCreate and execute cells inside a Jupyter notebook\n\n\n\n\n\n\n\nnotebooks\n\n\n\n\n\n\n\n\n\n\n\n2022-06-22\n\n\n\n\n\n\n\n\nSetting up TILs in Pelican\n\n\n\n\n\n\n\npelican\n\n\n\n\n\n\n\n\n\n\n\n2022-06-21\n\n\n\n\n\n\n\n\nUsing Pelican as a library\n\n\n\n\n\n\n\npelican\n\n\n\n\n\n\n\n\n\n\n\n2022-06-20\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tils/creating-a-minimal-custom-jupyter-widget.html",
    "href": "tils/creating-a-minimal-custom-jupyter-widget.html",
    "title": "Creating a minimal custom Jupyter widget",
    "section": "",
    "text": "I couldn‚Äôt find a super minimal example of implementing a custom Jupyter widget, so here it is. This is based on Pierre Marion‚Äôs Binder Repo for Hello World Jupyter Widget.\nimport ipywidgets as widgets\nfrom traitlets import Unicode, validate\n\n\nclass HelloWidget(widgets.DOMWidget):\n    _view_name = Unicode('HelloView').tag(sync=True)\n    _view_module = Unicode('hello').tag(sync=True)\n    _view_module_version = Unicode('0.1.0').tag(sync=True)\n    value = Unicode('Hello World!').tag(sync=True)\n%%javascript\nrequire.undef('hello');\n\ndefine('hello', [\"@jupyter-widgets/base\"], function(widgets) {\n\n    var HelloView = widgets.DOMWidgetView.extend({\n\n        render: function() { \n            this.el.textContent = this.model.get('value'); \n        },\n    });\n\n    return {\n        HelloView : HelloView\n    };\n});\nHelloWidget()"
  },
  {
    "objectID": "tils/creating-a-minimal-custom-jupyter-widget.html#further-reading",
    "href": "tils/creating-a-minimal-custom-jupyter-widget.html#further-reading",
    "title": "Creating a minimal custom Jupyter widget",
    "section": "Further reading",
    "text": "Further reading\nHere are some great articles that I referenced while exploring this topic:\n\nBinder Repo for Hello World Jupyter Widget\nAuthoring Custom Jupyter Widgets: A Hands-On Guide\nipywidgets Official Documentation: Building a Custom Widget - Email widget\nBinder Repo for Hello World Jupyter Widget\nIPython Notebook: Javascript/Python Bi-directional Communication. I think this may have been the birth of ipywidgets!"
  },
  {
    "objectID": "tils/using-shot-scraper.html",
    "href": "tils/using-shot-scraper.html",
    "title": "Using shot-scraper to automate screenshots for my writing",
    "section": "",
    "text": "I‚Äôm trying out Simon Willison‚Äôs shot-scraper to include a screenshot of the website for our JupyterCon 2023 tutorial in my blog post.\nFirst install the shot-scraper command line tool:\n\n!pip3 install shot-scraper\n\nCollecting shot-scraper\n  Downloading shot_scraper-1.2-py3-none-any.whl (15 kB)\nCollecting click\n  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 96.6/96.6 kB 3.7 MB/s eta 0:00:00\nRequirement already satisfied: PyYAML in /opt/homebrew/lib/python3.11/site-packages (from shot-scraper) (6.0)\nCollecting playwright\n  Downloading playwright-1.33.0-py3-none-macosx_11_0_arm64.whl (31.2 MB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 31.2/31.2 MB 5.5 MB/s eta 0:00:0000:0100:01\nCollecting click-default-group\n  Downloading click-default-group-1.2.2.tar.gz (3.3 kB)\n  Preparing metadata (setup.py) ... done\nCollecting greenlet==2.0.1\n  Downloading greenlet-2.0.1-cp311-cp311-macosx_10_9_universal2.whl (259 kB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 259.4/259.4 kB 5.3 MB/s eta 0:00:00a 0:00:01\nCollecting pyee==9.0.4\n  Downloading pyee-9.0.4-py2.py3-none-any.whl (14 kB)\nRequirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from pyee==9.0.4-&gt;playwright-&gt;shot-scraper) (4.5.0)\nBuilding wheels for collected packages: click-default-group\n  Building wheel for click-default-group (setup.py) ... done\n  Created wheel for click-default-group: filename=click_default_group-1.2.2-py3-none-any.whl size=3383 sha256=816707e9974b43b6f04f2e646cf851f2e041f0c7cc25fcb67612fb4d72973d4f\n  Stored in directory: /Users/seem/Library/Caches/pip/wheels/69/9a/ed/1979767796ee1379d161a35fea9745a788476be12fb2ac664a\nSuccessfully built click-default-group\nInstalling collected packages: pyee, greenlet, click, playwright, click-default-group, shot-scraper\nSuccessfully installed click-8.1.3 click-default-group-1.2.2 greenlet-2.0.1 playwright-1.33.0 pyee-9.0.4 shot-scraper-1.2\n\n[notice] A new release of pip is available: 23.0.1 -&gt; 23.1.2\n[notice] To update, run: python3.11 -m pip install --upgrade pip\n\n\nThen install the underlying browser used by shot-scraper:\n\n!shot-scraper install\n\nWe can now take a screenshot of any website!\n\n!shot-scraper https://fastai.github.io/jupytercon-2023/ --output ../posts/images/jupytercon-2023-tutorial.png --width 1600 --height 900\n\nHere‚Äôs the image:\n\n\n\n\n\nI want a resolution of 1600x900 but the font size is too small here. Halving the width and height and doubling the device scale factor with the --retina flag should fix this:\n\n!shot-scraper https://fastai.github.io/jupytercon-2023/ --output ../posts/images/jupytercon-2023-tutorial.png --width 800 --height 450 --retina\n\n\n\n\n\n\nFinally, I want to exclude the nav bar. We can use a CSS selector for that:\n\n!shot-scraper https://fastai.github.io/jupytercon-2023/ --output ../posts/images/jupytercon-2023-tutorial.png --selector '#quarto-content' --width 800 --height 450 --retina\n\n\n\n\n\n\nAh, it doesn‚Äôt seem like --selector works together with --width and --height. Another way to do this might be by hiding the navbar by executing --javascript code:\n\n!shot-scraper https://fastai.github.io/jupytercon-2023/ --output ../posts/images/jupytercon-2023-tutorial.png --width 800 --height 450 --retina --javascript \"document.querySelector('#quarto-header').style.display = 'none'\"\n\n\n\n\n\n\nPerfect! I‚Äôm chuffed with how easy this was. I typed this out exactly as I used it, and everything worked first time with zero errors. I think it would‚Äôve been neat if I could use --width and --height to crop the image after a --selector is applied, but in the end I could get what I wanted using a single line of --javascript."
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "",
    "text": "This is a walkthrough of the rather surprising mechanics underlying a failing test that brings together plugin modules (that register themselves on import), process pools, and Python‚Äôs import system."
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#what-went-wrong",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#what-went-wrong",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "What went wrong",
    "text": "What went wrong\nIt starts with a failed test:\npat = r\"\\[\\d, \\d+.\\d+, \\d+.\\d+, \\d+.\\d+, '\\d\\d:\\d\\d'\\]\"\ntest_stdout(lambda: learn.fit(1), pat, regex=True)\nThe idea is to test that calling learn.fit(1) writes text to stdout (standard output) that matches the regex pattern pat. For those less familiar, this form of testing is common in projects that use nbdev.\nHere‚Äôs what actually happens:\n\nThe nbprocess_test command creates a ProcessPoolExecutor with some number of workers and tasks (each notebook being a separate task).\nWorker 1 processes one task, say task 1, which creates an IPython InteractiveShell, then runs import fastai.callbacks.progress which adds ProgressCallback to the the variable fastcore.basics.defaults.\nWorker 1 processes another task, say task 3, which creates a fresh InteractiveShell, calls learner.fit, and tests stdout. Since ProgressCallback has been registered in this process by task 1, a progress bar is also printed to stdout, breaking the test.\n\nLet‚Äôs break down the underlying mechanics. There are three behaviours that come together to cause this sequence of events:\n\nProcessPoolExecutors reuse processes. It seems obvious in hindsight since that‚Äôs how pools usually work, but I had never realised it until now. In the example above, worker 1 executes task 1 and task 3 in the same process.\nfastai callbacks register themselves on import. In this case, fastai.callbacks.progress adds ProgressCallback to defaults.callbacks.\nChanges to imported modules persist across IPython InteractiveShells. nbprocess_test runs each test in parallel using execnb, which implements a sub-class of InteractiveShell.\n\nNext, we‚Äôll verify these behaviours with tiny experiments. I highly recommend using tiny experiments to understand complex systems."
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#processpoolexecutors-reuse-processes",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#processpoolexecutors-reuse-processes",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "ProcessPoolExecutors reuse processes",
    "text": "ProcessPoolExecutors reuse processes\nPerhaps we should know this simply from the name, but I didn‚Äôt, so we‚Äôll figure it out with a tiny experiment. Start by creating a pool with 2 max_workers:\n\nfrom concurrent.futures import ProcessPoolExecutor\n\npool = ProcessPoolExecutor(max_workers=2)\n\nThere aren‚Äôt any processes in the pool yet:\n\npool._processes\n\n{}\n\n\nSubmit a task: the function os.getpid, which will return the process ID of the worker that runs it. Since there are no processes in the pool, submit will start a new worker process, and have it execute the task. ProcessPoolExecutor.submit returns a Future object, and Future.result returns the task‚Äôs return value:\n\nimport os\n\nfuture = pool.submit(os.getpid)\nfuture.result()\n\n45907\n\n\nNo matter how many times you manually rerun the above cell, it will aways be executed on the same process. Notice that the process is now also available in the pool:\n\npool._processes\n\n{45907: &lt;SpawnProcess name='SpawnProcess-1' pid=45907 parent=45899 started&gt;}\n\n\nIf we submit another task:\n\nfuture = pool.submit(os.getpid)\nfuture.result()\n\n45907\n\n\n‚Ä¶it‚Äôs still executed on the same process.\nLet‚Äôs try executing two processes at the same time:\n\nfutures = [pool.submit(os.getpid) for _ in range(2)]\n[o.result() for o in futures]\n\n[45907, 45907]\n\n\nWeird. They‚Äôre both executed on the same process‚Ä¶\n\npool._processes\n\n{45907: &lt;SpawnProcess name='SpawnProcess-1' pid=45907 parent=45899 started&gt;,\n 45908: &lt;SpawnProcess name='SpawnProcess-2' pid=45908 parent=45899 started&gt;}\n\n\nIt looks like another process was started! I haven‚Äôt confirmed this, but I suspect that when we submitted two futures, the pool determined that it needed more workers, so it started another. However, the first worker‚Äôs task ended before the second worker started up, so the first worker processed both.\nSince we instantiated the pool with 2 max_workers, these two processes will execute all tasks, no matter how many we submit:\n\nfutures = [pool.submit(os.getpid) for _ in range(10)]\n[o.result() for o in futures]\n\n[45907, 45907, 45907, 45907, 45907, 45907, 45907, 45907, 45907, 45907]\n\n\nShutdown the pool to free up any resources:\n\npool.shutdown()"
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#fastai-callbacks-register-themselves-on-import",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#fastai-callbacks-register-themselves-on-import",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "fastai callbacks register themselves on import",
    "text": "fastai callbacks register themselves on import\nThis one is easy to demonstrate. defaults has no callbacks attribute to start with:\n\nfrom fastcore.basics import defaults\n\ndefaults\n\nnamespace(cpus=4)\n\n\ndefaults.callbacks is populated after importing ProgressCallback:\n\nfrom fastai.callback.progress import ProgressCallback\n\ndefaults\n\nnamespace(cpus=4,\n          benchmark=True,\n          use_cuda=None,\n          activation=torch.nn.modules.activation.ReLU,\n          callbacks=[fastai.callback.core.TrainEvalCallback,\n                     fastai.learner.Recorder,\n                     fastai.learner.CastToTensor,\n                     fastai.callback.progress.ProgressCallback],\n          lr=0.001)"
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#changes-to-imported-modules-persist-across-ipython-interactiveshells",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#changes-to-imported-modules-persist-across-ipython-interactiveshells",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "Changes to imported modules persist across IPython InteractiveShells",
    "text": "Changes to imported modules persist across IPython InteractiveShells\nWhy is any of the above a problem? Didn‚Äôt we say that nbprocess_test creates a separate shell for each notebook? Yes it does, but it turns out that changes to imported modules persist across shells.\n\nfrom execnb.shell import CaptureShell\n\nFirst make sure that CaptureShell doesn‚Äôt have a foo attribute - this will make sense in a second:\n\nassert not hasattr(CaptureShell, 'foo')\n\nNow add the foo attribute:\n\nCaptureShell.foo = 'bar'\n\nWe can see foo inside a CaptureShell:\n\nshell = CaptureShell()\nshell.run('from execnb.shell import CaptureShell; CaptureShell.foo')\nshell.result\n\n'bar'\n\n\nThis happens because when we first imported from the execnb.shell module it was cached in sys.modules:\n\nimport sys\n\nsys.modules['execnb.shell']\n\n&lt;module 'execnb.shell' from '/Users/seem/code/execnb/execnb/shell.py'&gt;\n\n\nIn fact, sys.modules['execnb.shell'].CaptureShell is another name for CaptureShell:\n\nsys.modules['execnb.shell'].CaptureShell is CaptureShell\n\nTrue\n\n\nPython caches imports to speed up consecutive imports from the same modules. InteractiveShell (and its sub-classes) have the same sys.modules which causes this behaviour:\n\nshell = CaptureShell()\nshell.run(\"import sys; sys.modules['execnb.shell'].CaptureShell.foo\")\nshell.result\n\n'bar'\n\n\nexec with empty globals and locals uses the same sys.modules too so it doesn‚Äôt avoid the issue:\n\nexec(\"import sys; print('execnb.shell' in sys.modules)\", {}, {})\n\nTrue\n\n\n\nexec(\"from execnb.shell import CaptureShell; print(CaptureShell.foo)\", {}, {})\n\nbar\n\n\n\nIn the end, we agreed that the test itself was broken, because it made assumptions about its environment without ensuring that they were true. Tests like this may fail - regardless of the above behaviour - if we import any module that registers a callback. For example, this fails too:\nfrom fastai.callback.progress import *\nfrom nbprocess.test import test_nb\n\ntest_nb('nbs/nb_with_failing_test.ipynb')\nThe fix is to explicitly run learner.fit with the precise list of callbacks required."
  },
  {
    "objectID": "tils/how-to-create-an-ai-profile-picture-from-scratch.html",
    "href": "tils/how-to-create-an-ai-profile-picture-from-scratch.html",
    "title": "How to create your own AI avatar using HuggingFace Diffusers and Dreambooth",
    "section": "",
    "text": "I‚Äôm super impressed with the quality of Dreambooth using HuggingFace Diffusers üöÄ ‚Äî with only 14 images of myself! These four images are created by Stable Diffusion using the same fine-tuned model with different prompts:1\n\n\n\nFour AI-generated pictures of me.\n\n\nHere are a few details that made the difference for me:\n\nHigh-quality data: As always, the most crucial element is data. I got away with very few images, but quality is important. I used:\n\n14 images\nCaptured around the same time, therefore same facial structure, hairstyle, etc\nCropped to head & shoulders\nI was the only subject\n\nAvoid overfitting: Second most important is to avoid overfitting. I used:\n\nPrior preservation loss with 90 high quality portraits scraped from Pexel via the yuvalkirstain/portrait_dreambooth HuggingFace dataset\nLow learning rate (1e-6)\nLow training step count (300) ‚Äì adjust this based on how many images you have\n\nTrain the text encoder: In addition to the U-Net. I needed to use a few of the supported memory optimization features to run this on a 16GB GPU:\n\nXformers‚Äô efficient attention ‚Äì had to build from source, prebuilt didn‚Äôt work\nHuggingFace Accelerate‚Äôs gradient accumulation\nBitsandbytes‚Äô 8bit adam\n\nHigh-quality prompts: If you do all of the above perfectly, you still won‚Äôt get great results without high quality prompts. I‚Äôm not a prompt guru myself, so I took from the excellent prompts curated at PublicPrompts as well as Lexica.\nEven with great prompts, it is a struggle to get it to deviate from the training set. I had to tweak the order of words, and try adding and removing certain words to get it to work. For some reason, adding ‚ÄúHypnotic illustration‚Äù to the start of the prompt worked consistently ü§∑üèΩ‚Äç‚ôÇÔ∏è.\n\nPlease don‚Äôt hestitate to share any questions or comments in the Twitter thread below or via email:\n\n\nI'm super impressed with the quality of Dreambooth with @huggingface Diffusers üöÄ using only 14 pics of myself!All of these are generated, with different prompts for: plain photo, psy art, anime, toy storyWhat worked for me:1. As always, the most crucial element is data‚Ä¶ pic.twitter.com/ueZd13AuwR\n\n‚Äî Wasim Lorgat (@wasimlorgat) March 6, 2023\n\n\n\n\n\n\n\nHere are the exact prompts I used for each of the above images:\n\nTop-left: a photo of &lt;dreambooth token&gt;\nTop-right: Hypnotic illustration of &lt;dreambooth token&gt;, hypnotic psychedelic art by Dan Mumford, pop surrealism, dark glow neon paint, mystical, Behance (PublicPrompts source)\nBottom-left: Hypnotic illustration of &lt;dreambooth token&gt;, anime illustration by makoto shinkai, stanley artgerm lau, wlop, rossdraws, concept art, digital painting (PublicPrompts source)\nBottom-right: Toy Story‚Äôs Woody as &lt;dreambooth token&gt;, 4k, artstation, cgsociety, award-winning, masterpiece, stunning, beautiful, glorious, powerful, fantasy art by Greg Rutkowski, octane render, unreal engine, high (Lexica source)\n\n‚Ü©Ô∏é"
  },
  {
    "objectID": "tils/how-to-use-nstableview-in-swiftui.html",
    "href": "tils/how-to-use-nstableview-in-swiftui.html",
    "title": "How to use NSTableView in SwiftUI",
    "section": "",
    "text": "I recently started learning macOS development using SwiftUI as part of my latest project: building a macOS Jupyter frontend. While I‚Äôm loving Swift (the language) and SwiftUI (the UI framework), it‚Äôs sometimes extremely difficult to find out information that feels like it should be readily available.\nThe latest such case is how to use an NSTableView in SwiftUI. SwiftUI‚Äôs new List is great for iOS and multiplatform apps, but doesn‚Äôt seem to be designed for desktop-specific apps which can do with much more information-dense UIs.\nSwiftUI has the newer Table too, but it‚Äôs also quite limited at this stage. For example, I don‚Äôt think it‚Äôs possible to make an entire row clickable.\nThis left me wanting to try out the much more battle-tested NSTableView ‚Äì but as an Apple dev noob, I couldn‚Äôt get a minimal example up and running after a few hours of tinkering!\n‚Ä¶ So here‚Äôs a snippet you can copy paste.1 Keep reading below if you‚Äôd like to see how it works step-by-step.\nimport SwiftUI\n\nstruct TableView: NSViewRepresentable {\n    class Coordinator: NSObject, NSTableViewDelegate, NSTableViewDataSource {\n        let data = [\"Apple\", \"Banana\", \"Cherry\"]\n\n        func numberOfRows(in tableView: NSTableView) -&gt; Int {\n            data.count\n        }\n\n        func tableView(_ tableView: NSTableView, viewFor tableColumn: NSTableColumn?, row: Int) -&gt; NSView? {\n            NSTextField(labelWithString: data[row])\n        }\n    }\n\n    func makeCoordinator() -&gt; Coordinator {\n        Coordinator()\n    }\n\n    func makeNSView(context: Context) -&gt; NSTableView {\n        let tableView = NSTableView()\n        tableView.delegate = context.coordinator\n        tableView.dataSource = context.coordinator\n        tableView.addTableColumn(NSTableColumn())\n        return tableView\n    }\n\n    func updateNSView(_ nsView: NSTableView, context: Context) {\n        // Do nothing\n    }\n}\nStep-by-step:\nCreate your table view struct, conforming to NSViewRepresentable. This is a standard way of using AppKit/UIKit views in your SwiftUI applications.\nIn makeNSView, create the NSTableView with a single column, and leave updateNSView blank for now:\nstruct TableView: NSViewRepresentable {\n    func makeNSView(context: Context) -&gt; NSTableView {\n        let tableView = NSTableView()\n        tableView.addColumn(NSTableColumn())\n        return tableView\n    }\n\n    func updateNSView(_ nsView: NSTableView, context: Context) {\n        // Do nothing\n    }\n}\nCreate a Coordinator, subclassing:\n\nNSTableViewDelegate which we‚Äôll use to customize how cells are rendered as views, and\nNSTableViewDataSource to define the number of rows.\n\nImplement makeCoordinator, returning an instance of Coordinator, then link it to the table view in makeNSView:\nstruct TableView: NSViewRepresentable {\n    class Coordinator: NSObject, NSTableViewDelegate, NSTableViewDataSource {\n    }\n\n    func makeCoordinator() -&gt; Coordinator {\n        Coordinator()\n    }\n\n    func makeNSView(context: Context) -&gt; NSTableView {\n        let tableView = NSTableView()\n        tableView.delegate = context.coordinator\n        tableView.dataSource = context.coordinator\n        tableView.addColumn(NSTableColumn())\n        return tableView\n    }\n\n    func updateNSView(_ nsView: NSTableView, context: Context) {\n        // Do nothing\n    }\n}\nYou still won‚Äôt see anything being rendered yet, since we still need to implement NSTableViewDelegate and NSTableViewDataSource methods.\nFor this minimal example, we‚Äôll use a simple static array of strings defined right in the coordinator, although in practice you would probably get data from the view.\nImplement NSTableViewDataSource‚Äôs numberOfRows and NSTableViewDelegate‚Äôs tableView(tableView:viewFor:row). The former returns the length of our array. The latter returns an NSTextField created from the corresponding row of data.\n    class Coordinator: NSObject, NSTableViewDelegate, NSTableViewDataSource {\n        let data = [\"Apple\", \"Banana\", \"Cherry\"]\n\n        func numberOfRows(in tableView: NSTableView) -&gt; Int {\n            data.count\n        }\n\n        func tableView(_ tableView: NSTableView, viewFor tableColumn: NSTableColumn?, row: Int) -&gt; NSView? {\n            NSTextField(labelWithString: data[row])\n        }\n    }\nThat‚Äôs it! This is the minimal implementation of an NSTableView in SwiftUI that I could find. Let me know on Twitter, via email, or via the GitHub discussion below if you have any comments or suggestions.\nHere are some next steps I have in mind:\n\nGet preview working (this looks helpful)\nCustom cell view\n\nVertically align text\n\nMultiple columns\n\nIndex column\nImage column\nDate column\n\nColumn headers\nMake it interactive\n\nDo something on select\nDo something on hover\nDo something on click\n\nLoad data dynamically\n\nLet me know if you‚Äôd find these helpful!\n\n\n\n\n\n\nMany thanks to Alex Grebenyuk whose article and repo I heavily referenced to figure this out.‚Ü©Ô∏é"
  },
  {
    "objectID": "tils/update-fastai-union-annotations-using-ast.html",
    "href": "tils/update-fastai-union-annotations-using-ast.html",
    "title": "Update fastai union annotations using ast",
    "section": "",
    "text": "This notebook doesn‚Äôt render correctly until I figure out how to tell Quarto to echo code cells as is without parsing directives.\n\n\nThis notebook defines and exports a lightweight command line tool that updates union annotations in notebooks from the fastai tuple style (x:(int,str)) to the Python 3.10 union operator (x:int|str), using the ast standard library, and developed with nbdev.\n::: {#85b7db48 .cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô}\nimport ast\nimport sys\nfrom execnb.nbio import read_nb, write_nb\n:::\n\nfrom fastcore.test import test_eq\n\n::: {#2e20197a .cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô}\ndef tuple2bitor(annot):\n    \"Convert fastai tuple style union annotation to py310 union operator\"\n    bitor = annot.dims[0]\n    for right in annot.dims[1:]: bitor = ast.BinOp(left=bitor, right=right, op=ast.BitOr())\n    return bitor\n\ndef tuple2bitorstr(annot): return ast.unparse(tuple2bitor(annot)).replace(' ', '')\n:::\n\na = ast.Tuple([ast.Name(id=o) for o in ('int','str','float')])\ntest_eq(ast.unparse(a),'(int, str, float)')\ntest_eq(tuple2bitorstr(a),'int|str|float')\n\n::: {#938e7d41 .cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô}\ndef split_parts(source, node):\n    \"Split `source` into parts before, containing, and after `node`\"\n    lines = source.split('\\n')\n    assert node.lineno == node.end_lineno, 'Multi-line annotations not supported'\n    l = node.lineno-1\n    line = lines[l]\n    s,e = node.col_offset, node.end_col_offset\n    return '\\n'.join(lines[:l]+[line[:s]]), line[s:e], '\\n'.join([line[e:]]+lines[l+1:])\n:::\n\ns = '''\ndef f(\n    x: (int, str, float),\n    y=5\n): pass'''\nn = ast.parse(s)\na = n.body[0].args.args[0].annotation\nps = split_parts(s, a)\ntest_eq(ps, ('\\ndef f(\\n    x: ', '(int, str, float)', ',\\n    y=5\\n): pass'))\n\n::: {#97788e4e .cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô}\ndef replace_node(source, node, repl):\n    \"Replace `node` in `source` with `repl`\"\n    parts = split_parts(source, node)\n    return parts[0] + repl + parts[2]\n:::\n\ntest_eq(replace_node(s, a, tuple2bitorstr(a)), '\\ndef f(\\n    x: int|str|float,\\n    y=5\\n): pass')\n\n::: {#373ffcf2 .cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô}\ndef fix_tuple_annots(source):\n    \"Convert all fastai tuple style union annotations in `source` to py310 union operator\"\n    while True:\n        n = ast.parse(source)\n        try: a = next(o.annotation for o in ast.walk(n) if isinstance(getattr(o,'annotation',None),ast.Tuple))\n        except StopIteration: return source\n        source = replace_node(source, a, tuple2bitorstr(a))\n:::\n\ns = '''\n@patch\ndef crop_pad(x:TensorBBox|TensorPoint|Image.Image,\n    sz:(int, tuple), # Crop/pad size of input, duplicated if one value is specified\n    tl:tuple=None, # Optional top-left coordinate of the crop/pad, if `None` center crop\n    orig_sz:tuple=None, # Original size of input\n    pad_mode:PadMode=PadMode.Zeros, # Fastai padding mode\n    resize_mode=BILINEAR, # Pillow `Image` resize mode\n    resize_to:tuple=None # Optional post crop/pad resize of input\n):\n    if isinstance(sz,int): sz = (sz,sz)\n    orig_sz = fastuple(_get_sz(x) if orig_sz is None else orig_sz)\n    sz,tl = fastuple(sz),fastuple(((_get_sz(x)-sz)//2) if tl is None else tl)\n    return x._do_crop_pad(sz, tl, orig_sz=orig_sz, pad_mode=pad_mode, resize_mode=resize_mode, resize_to=resize_to)\n'''\n\ntest_eq(fix_tuple_annots(s), '''\n@patch\ndef crop_pad(x:TensorBBox|TensorPoint|Image.Image,\n    sz:int|tuple, # Crop/pad size of input, duplicated if one value is specified\n    tl:tuple=None, # Optional top-left coordinate of the crop/pad, if `None` center crop\n    orig_sz:tuple=None, # Original size of input\n    pad_mode:PadMode=PadMode.Zeros, # Fastai padding mode\n    resize_mode=BILINEAR, # Pillow `Image` resize mode\n    resize_to:tuple=None # Optional post crop/pad resize of input\n):\n    if isinstance(sz,int): sz = (sz,sz)\n    orig_sz = fastuple(_get_sz(x) if orig_sz is None else orig_sz)\n    sz,tl = fastuple(sz),fastuple(((_get_sz(x)-sz)//2) if tl is None else tl)\n    return x._do_crop_pad(sz, tl, orig_sz=orig_sz, pad_mode=pad_mode, resize_mode=resize_mode, resize_to=resize_to)\n''')\n\n::: {#4d7c66ca .cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô}\ndef fix_nb_tuple_annots(nb):\n    \"Convert all fastai tuple style union annotations in `nb` to py310 union operator\"\n    for cell in nb.cells:\n        try: cell.source = fix_tuple_annots(cell.source)\n        except SyntaxError: pass\n:::\n::: {#a230fa3b .cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô}\nfrom fastcore.script import *\nfrom fastcore.utils import *\n\n@call_parse\ndef main(fname:str): # A notebook name or glob to convert\n    \"Convert all fastai tuple style union annotations in `nb_path` to py310 union operators\"\n    for f in globtastic(fname, file_glob='*.ipynb', skip_folder_re='^[_.]'):\n        nb = read_nb(f)\n        fix_nb_tuple_annots(nb)\n        write_nb(nb, f)\n:::"
  },
  {
    "objectID": "tils/create-and-execute-cells-inside-a-jupyter-notebook.html",
    "href": "tils/create-and-execute-cells-inside-a-jupyter-notebook.html",
    "title": "Create and execute cells inside a Jupyter notebook",
    "section": "",
    "text": "I‚Äôve been thinking a lot about unique Jupyter notebook interactions. A pattern that keeps coming up in my head is to click on the output of one cell to create a new cell below it. For example, ls() could output file and directory widgets for the current directory. Clicking on a directory widget, say foo, could create a code cell below with code ls(foo), to interactively browse through files.\n\n\n\n\n\n\nUpdate (2022-06-23)\n\n\n\nI‚Äôve created a working demo of point-and-click directory navigation using this pattern!.\n\n\nI found this amazing gist by Fernando Perez (originally by Jonathan Frederic, see the gist for more links) which enables this pattern! It turns out that IPython makes this pretty straightforward. You directly execute JavaScript code against the IPython API that creates a code cell, sets the text of the cell (which must be base64 encoded), then executes it:\n\nimport base64\nfrom IPython.display import Javascript\nfrom ipywidgets import Button\n\ndef create_code_cell():\n    code = \"print('Hello world!')\"\n    encoded_code = base64.b64encode(code.encode()).decode()\n    display(Javascript(f'''\n        var code = IPython.notebook.insert_cell_below('code');\n        code.set_text(atob(\"{encoded_code}\"));\n        code.execute();\n    '''))\n\ncreate_code_cell()\n\n\n\n\n\nprint('Hello world!')\n\nHello world!\n\n\nI didn‚Äôt know that there was a neat JavaScript API inside Jupyter notebooks, but it does make sense that it exists. It‚Äôs also really useful to browse the API using your browser‚Äôs console via auto-complete on the IPython object:"
  },
  {
    "objectID": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html",
    "href": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html",
    "title": "Point and click directory navigation inside a Jupyter notebook",
    "section": "",
    "text": "Here‚Äôs a tiny demo of a point-and-click navigation interface with rich output powered by Jupyter notebooks and ipywidgets! I originally mentioned the idea in a previous TIL. I also tweeted about it which is the best place to leave any comments or questions if you‚Äôd like."
  },
  {
    "objectID": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#tldr",
    "href": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#tldr",
    "title": "Point and click directory navigation inside a Jupyter notebook",
    "section": "TL;DR",
    "text": "TL;DR\nIf all you need is a copy-pastable code snippet, here you go. Read on for a more in-depth description.\n\nfrom base64 import b64encode\nfrom functools import partial\nfrom IPython.display import Javascript, display\nfrom ipywidgets import Box, Button, Layout\nfrom pathlib import Path\n\ndef create_code_cell(code):\n    encoded_code = b64encode(code.encode()).decode()\n    display(Javascript(f\"\"\"\n        var code = IPython.notebook.insert_cell_below('code');\n        code.set_text(atob(\"{encoded_code}\"));\n        code.execute();\n        code.focus_cell()\"\"\"))\n\ndef on_click_dir(path, button): create_code_cell(f\"ls('{path}')\")\ndef on_click_file(path, button): create_code_cell(f\"Path('{path}')\")\n\ndef ls(root=Path()):\n    if isinstance(root, str): root = Path(root).expanduser()\n    paths = sorted(root.iterdir())\n    if not paths: return\n    button_layout = Layout(width='fit-content')\n    buttons = []\n    for path in paths:\n        button = Button(description=str(path.relative_to(root)), layout=button_layout)\n        button.on_click(partial(on_click_dir if path.is_dir() else on_click_file, path))\n        buttons.append(button)\n    box_layout = Layout(overflow='scroll hidden', height='500px', display='flex',\n                        flex_flow='column wrap', align_content='flex-start')\n    return Box(buttons, layout=box_layout)"
  },
  {
    "objectID": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#minimal-implementation",
    "href": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#minimal-implementation",
    "title": "Point and click directory navigation inside a Jupyter notebook",
    "section": "Minimal implementation",
    "text": "Minimal implementation\nWe start by defining a function to create and execute a code cell below the focused cell (see my previous TIL if you‚Äôd like more detail on this part):\n\ndef create_code_cell(code):\n    encoded_code = b64encode(code.encode()).decode()\n    display(Javascript(f\"\"\"\n        var code = IPython.notebook.insert_cell_below('code');\n        code.set_text(atob(\"{encoded_code}\"));\n        code.execute();\n        code.focus_cell()\n    \"\"\"))\n\nWe‚Äôre going to be using button widgets, which expect an on-click callback, so let‚Äôs define those next. The callback is expected to be a function accepting a single argument, button, to which the button object itself is passed - although we won‚Äôt be using it. We need to know the path that was clicked on as well, so we‚Äôll have to partial that in later:\n\ndef on_click_dir(path, button): create_code_cell(f\"ls('{path}')\")\ndef on_click_file(path, button): create_code_cell(f\"Path('{path}')\")\n\nTest if it works:\n\non_click_file(Path('point-and-click-directory-navigation-inside-a-jupyter-notebook.ipynb'), None)\n\n\n\n\n\nPath('point-and-click-directory-navigation-inside-a-jupyter-notebook.ipynb')\n\nPosixPath('point-and-click-directory-navigation-inside-a-jupyter-notebook.ipynb')\n\n\nNeat! The cell above this was created by calling on_click_file.\nFinally, we implement a straightforward minimal ls function using Button widgets for Paths, and wrapping those in a VBox widget:\n\nfrom ipywidgets import VBox\n\ndef ls(root=Path()):\n    if isinstance(root, str): root = Path(root).expanduser()\n    paths = sorted(root.iterdir())\n    if not paths: return\n    buttons = []\n    for path in paths:\n        button = Button(description=str(path))\n        button.on_click(partial(on_click_dir if path.is_dir() else on_click_file, path))\n        buttons.append(button)\n    return VBox(buttons)"
  },
  {
    "objectID": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#improved-styling",
    "href": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#improved-styling",
    "title": "Point and click directory navigation inside a Jupyter notebook",
    "section": "Improved styling",
    "text": "Improved styling\nI don‚Äôt like how the implementation above is styled, so here is another with a few purely stylistic improvements:\n\ndef ls(root=Path()):\n    if isinstance(root, str): root = Path(root).expanduser()\n    paths = sorted(root.iterdir())\n    if not paths: return\n    button_layout = Layout(width='fit-content')\n    buttons = []\n    for path in paths:\n        button = Button(description=str(path.relative_to(root)), layout=button_layout)\n        button.on_click(partial(on_click_dir if path.is_dir() else on_click_file, path))\n        buttons.append(button)\n    box_layout = Layout(overflow='scroll hidden', height='500px', display='flex',\n                        flex_flow='column wrap', align_content='flex-start')\n    return Box(buttons, layout=box_layout)\n\n\nls('~/code/fastai')\n\n\n\n\nUnfortunately, my current blog setup doesn‚Äôt support widgets, but you should be able to run this locally. You can also check out the demo video in my tweet.\nIf you pay close attention to the demo video, you‚Äôll notice that it‚Äôs still styled slightly differently to what we‚Äôve built here. Some styles can‚Äôt be changed through ipywidget‚Äôs style interface, so that was achieved by manually writing CSS with the %%html magic command followed by a &lt;style&gt;...&lt;/style&gt; tag, and then assigning a class to the buttons and boxes using their add_class method. I also implemented a custom widget with a small render JavaScript function that resized the output grid until it fit the width of the screen.\nI‚Äôm really excited with how this turned out! And it was far simpler than I‚Äôd expected. I‚Äôll definitely be exploring the point-and-click navigation pattern more. I‚Äôm thinking about trying it out for exploring documentation about Python objects."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nHi, I‚Äôm Wasim\n",
    "section": "",
    "text": "Hi, I‚Äôm Wasim\nI‚Äôm a software engineer and data scientist.\nThis is where I share lessons learned during my projects, spanning notebook-driven development, artificial intelligence and software design.\nYou might also be interested in my full list of side projects and notes.\nPreviously, I held technical leadership positions in South African AI startups in manufacturing and agriculture. Before that, I was a professional DotA 2 player."
  },
  {
    "objectID": "index.html#get-in-touch",
    "href": "index.html#get-in-touch",
    "title": "\nHi, I‚Äôm Wasim\n",
    "section": "Get in touch",
    "text": "Get in touch\nOne of my biggest motivations for sharing online is to connect with interesting people from across the world.\nEmail me at mwlorgat@gmail.com or DM me on Twitter or LinkedIn if you‚Äôd like to chat!"
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "\nHi, I‚Äôm Wasim\n",
    "section": "Recent posts",
    "text": "Recent posts\nMastodon verification"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "My projects span machine learning, programming languages, personal analytics, browser extensions, code editors, and personal tools to support my workflows. I work on projects for fun, to learn, or to solve a specific problem I have. More recent projects are listed first.\nClick on a project‚Äôs heading to go to its website/repo."
  },
  {
    "objectID": "projects.html#section",
    "href": "projects.html#section",
    "title": "Projects",
    "section": "2022",
    "text": "2022\n\nMeepo\nA smarter search engine for a local (South African) fashion and homeware store.\nI have no affiliation with said store. I built this for myself, because I was frustrated at how difficult it was to find what I wanted with the existing search engine + I was curious how well CLIP (a relatively new AI technique with open source code and models) would work here.\nI think it works quite well! It‚Äôs much more forgiving than the original search engine. I don‚Äôt have to guess what exactly they decided to label a particular item. But what I like even more is that it works quite well for abstract things like ‚Äúcolourful shoes‚Äù.\nHere‚Äôs the full stack:\n\nHardware: Deployed on a 2CPU 4GB RAM VPS with docker\nStorage: SQLite + object storage (for images)\nSearch: CLIP text/image neural networks + faiss similarity search index\nPipeline: Python scripts + cron\nWeb: Django serving HTML/Tailwind/daisyUI\nIDE: Developed in notebooks with nbdev\n\nI tried to keep the implementation as simple as possible and I‚Äôm happy with the result! It took ~2 weeks to build and has been running seamlessly without my input ever since.\nCheck out this Twitter thread for more details.\n\n\nnbdev\nI‚Äôm a core developer of nbdev, an open source notebook-driven software development platform.\nnbdev let‚Äôs me use exploratory programming (related to REPL-driven development and literate programming) for all of my software development.\nI also came up with the idea of hooking into the Jupyter file save API and using a custom git merge driver to improve Jupyter/git integration. All of the core functionality used by these hooks was already implemented by other nbdev core developers. You can find out more in the write-up.\n\n\nPlum dispatch for fastcore (experimental)\nAn experimental PR to fastcore (the core library powering the fastai deep learning framework), that replaces its custom type dispatch system with plum-dispatch. Both bring Julia‚Äôs multiple dispatch into Python using type annotations and decorators."
  },
  {
    "objectID": "projects.html#section-1",
    "href": "projects.html#section-1",
    "title": "Projects",
    "section": "2021",
    "text": "2021\n\nEasyEquities browser extension\nA browser extension for the EasyEquities investment platform built with TypeScript, React, React Router, and Mock Service Worker (to develop against a mocked version of their API).\nThis started with frustration that EasyEquities didn‚Äôt provide a single view of my holdings across all of my investment accounts, nor of my time-weighted returns. I made good progress but stopped building this since there‚Äôs no public EasyEquities API, and sending handcrafted requests to the internal API of my investment platform seems like a bad idea!\n\n\nRepo links\nA tiny command-line tool to quickly open URLs related to your repos. I made this for a smoother experience while working on a manyrepo codebase.\n\n\nMyFitnessPal to SQLite\nSave your personal data from MyFitnessPal to a SQLite database. I occasionally use MyFitnessPal to track my weight and calories. Inspired by the dogsheep movement, I built this to afford personal analytics on my own data.\n\n\nCircleCI to SQLite\nSave your personal data from CircleCI to a SQLite database. I threw this together for a quick analysis on build times at a former workplace, which we could then follow up with easy build pipeline optimisations.\n\n\nReverse engineering ncode\nAn attempt at reverse engineering ncode paper technology. I got all the way down from what looked like dots on paper to a matrix which I needed to decode. Perhaps I‚Äôll get back to it some day!\n\n\nRomulus\nAn experimental framework for creating structure-aware editors. The idea was that actions (e.g.¬†move left, insert character) would be aware of the context surrounding the cursor location within the (tree-)structured document, thus would have slightly more intelligent behaviour.\nFor example, given a document ((foo)|, where | represents the cursor, and where ((foo)) is a known symbol represented some BlockRef object, inserting ) would know to create a BlockRef object in the internal tree structure. Like a hackier version of tree sitter. The vision was to use this framework to create a Roam clone using an enhanced markdown-like syntax for personal use.\n\n\nZip\nFunctional hierarchical zipper (tree cursor), with navigation, editing, and enumeration. A port of clojure.zip to JavaScript that I intended to use in Romulus.\n\n\nRoam tools\nTiny command-line tools for working with Roam graphs.\n\n\nRoam parser\nA tiny Roam parser built with Clojure and instaparse. I also live tweeted the entire development process.\n\n\nImage alignment\nKeypoint-based alignment of two grayscale images using ORB and RANSAC via skimage. This was completed as a take-home assignment for a job application, so I limited the implementation to a max of 8 hours."
  },
  {
    "objectID": "projects.html#section-2",
    "href": "projects.html#section-2",
    "title": "Projects",
    "section": "2020",
    "text": "2020\n\nEditor\nMinimal terminal text editor written in Python and curses. I wrote a corresponding step-by-step tutorial as well.\n\n\nAdvent of Code\nI enjoyed taking part in AoC for years 2017, 2018, 2019, and 2020.\n\n\nAlfred Github local\nAn Alfred workflow to open GitHub repo URLs via a local workspace directory. No GitHub API access needed!\n\n\npdlog\nSeamless logging for pandas dataframe operations, inspired by tidylog. We used pandas in production extensively at a former workplace, and our code often ended up overwhelmed with logging logic. With pdlog it‚Äôs simple: instead of calling, say, df.dropna(), call df.log.dropna() and it‚Äôll log &lt;pdlog&gt; dropna: dropped 1 row (17%), 5 rows remaining."
  },
  {
    "objectID": "projects.html#section-3",
    "href": "projects.html#section-3",
    "title": "Projects",
    "section": "2018",
    "text": "2018\n\nNeural networks from scratch\nA basic implementation of neural networks from scratch. Shortly after my encounter with reinforcement learning (see below), I realised that deep learning was an important precursor and shifted my studies there.\n\n\nReinforcement learning from scratch\nRe-implementing sections of Sutton and Barto‚Äôs Reinforcement Learning: An Introduction. My first inspiration in AI was the possibility that a computer could play games better than the best humans! I was determined to build one of these AIs myself."
  },
  {
    "objectID": "posts/how-to-build-your-own-vector-search-engine.html",
    "href": "posts/how-to-build-your-own-vector-search-engine.html",
    "title": "How to build your own vector search engine",
    "section": "",
    "text": "I built a vector search engine named Meepo for a local (South African üáøüá¶) eCommerce store. Thanks to the power and availability of foundational neural networks, open-source software, and cloud infrastructure ‚Äì along with a touch of good planning ‚Äì the entire process took me just one week, and it costs me a mere $30 per month to host.\nHonestly, it blows my mind that this is possible. Decades of hard work by some of the brightest minds have enabled us to create and distribute incredible AI-powered products from almost anywhere in the world.\nIn this post, I show you how to build your own vector search engine.\nBy the end of the post you‚Äôll be able to search through a dataset of pet images for queries as obscure as ‚Äúa fluffy pink cat on a tv‚Äù ‚Äì and it‚Äôll work! You‚Äôll also have a concrete idea of how to structure and deploy your own search engine.\nWe‚Äôll get there in three parts:"
  },
  {
    "objectID": "posts/how-to-build-your-own-vector-search-engine.html#part-1-background",
    "href": "posts/how-to-build-your-own-vector-search-engine.html#part-1-background",
    "title": "How to build your own vector search engine",
    "section": "Part 1: Background",
    "text": "Part 1: Background\n\nWhy do we need vector search?\nI built Meepo out of frustration with existing search engines. I needed a fork, so naturally I tried to search for ‚Äúfork‚Äù on my favourite online store, but the result contained only 4 items ‚Äì none of which resemble a fork at all!\n\nIt turns out, I had to search ‚Äúcutlery‚Äù instead, because that‚Äôs how the items happen to be tagged in the store‚Äôs catalogue.\nOn the other hand, here are the first few results with Meepo. So many forks!\n\nWhy the difference?\nWhereas conventional search engines work by matching the text in your query with labels attached to each image, modern semantic search engines leverage neural networks for a deeper understanding of what‚Äôs represented by the pixels in the image and the text in their labels.\nThis means that queries like ‚Äúfork‚Äù work, regardless of how each item is labelled. It also means that you can get far more creative with your queries, including colors, textures, patterns, and more!\nFor example, here is the top search result for ‚Äúfluffy striped salmon pillow‚Äù:\n\n\n\n\n\nIncredible! And even more incredible is how easy it is to build your own such vector search engine thanks to a powerful and open-source technology: Contrastive Language-Image Pretraining (CLIP).\n\n\nWhat‚Äôs CLIP?\nContrastive Language-Image Pretraining (CLIP) is a technique for training neural networks with state-of-the-art zero-shot performance on a variety of tasks using mixed image and text data.11¬†While CLIP has been dethroned several times in the last two years (most recently by BLIP-2), it is still notable for introducing a step change improvement in the power of zero-shot multimodal techniques.\nZero-shot learning refers to a machine learning approach where a model is trained on one dataset and then tested on a completely different dataset. For instance, CLIP was trained on a broad dataset of captioned images from the web. However, in the next section we will apply it to a dataset featuring only cats and dogs. Meepo similarly applies CLIP to images of homeware and fashion items.\n\n\n\nA visualization of the contrastive language-image pretraining approach. Source: CLIP: Connecting Text and Images by OpenAI.\n\n\nThe idea is to pretrain a neural network to predict the most relevant text snippet given an image and vice versa.\nBut the trick is to use a contrastive rather than a predictive objective.\nWhat does that mean?\nA predictive objective takes an input image and tries to predict its corresponding text snippet.\nOn the other hand, a contrastive objective predicts a vector for each image and another vector for each text snippet; these vectors are called embeddings. It does so in such a way that corresponding image and text vectors are more similar (according to some chosen similarity function) and non-corresponding image and text vectors are less similar.\nOpenAI found that a contrastive objective reached the same zero-shot ImageNet accuracy as the predictive objective while using 4x fewer training examples!\n\n\nConVIRT: The little-known medical roots of CLIP\nInterestingly, the technique described above was originally introduced as ConVIRT (Zhang et al.¬†2020), which demonstrated the approach on 217k medical image-text pairs (~2000x fewer than CLIP).\n\n\n\nX-ray images with naturally occurring paired descriptions from doctor‚Äôs reports. Source: Figure 1 of Zhang et al., 2020\n\n\nDespite being acknowledged in the CLIP paper, I hadn‚Äôt heard of ConVIRT until I read the CLIP paper myself:\n\n[‚Ä¶] we create a new dataset of 400 million (image, text) pairs and demonstrate that a simplified version of ConVIRT trained from scratch, which we call CLIP, for Contrastive Language-image Pre-training, is an efficient method of learning from natural language supervision.\n\nAs with most machine learning innovations, it all starts with data. High-quality annotations of medical images are expensive to make.\nConVIRT‚Äôs key insight was to mine doctor‚Äôs reports in their natural language format for image-text pairs.\nOpenAI‚Äôs later contribution was largely an engineering effort. They scaled ConVIRT up to a 2000x larger dataset‚Äî400 million examples in total! Of course, that itself is a mighty task.\nNow that we have some background on CLIP and its impressive zero-shot capabilities, how do we actually use it to create a semantic search engine like Meepo?"
  },
  {
    "objectID": "posts/how-to-build-your-own-vector-search-engine.html#part-2-lets-build-a-clip-search-engine-for-the-oxford-pets-dataset",
    "href": "posts/how-to-build-your-own-vector-search-engine.html#part-2-lets-build-a-clip-search-engine-for-the-oxford-pets-dataset",
    "title": "How to build your own vector search engine",
    "section": "Part 2: Let‚Äôs build a CLIP search engine for the Oxford Pets dataset",
    "text": "Part 2: Let‚Äôs build a CLIP search engine for the Oxford Pets dataset\nIn this section, we‚Äôll build our own CLIP-based semantic search engine on the Oxford Pets dataset.\nI chose the Oxford Pets dataset since it‚Äôs a good size and complexity to demonstrate the power of CLIP, but I urge you to try this out on your own dataset too.\nWe‚Äôll do this in two steps:\n\nFirst, we‚Äôll use CLIP as a convenient zero-shot classifier.\nThen we‚Äôll show how to use the same underlying functions for text-to-image search.\n\nBy the end of the section you will be able to search for queries as obscure as ‚Äúa fluffy pink cat on a tv‚Äù ‚Äì and it‚Äôll work!\n\nThe Oxford Pets dataset\nFirst install these required libraries:\n\nHuggingFace Datasets: easily access and share datasets for a variety of machine learning tasks.\nHuggingFace Transformers: easily download, train, and use state-of-the-art pretrained neural networks.\n\n\n!pip install datasets transformers\n\nThen load the Oxford Pets dataset ‚Äì thanks to Pedro Cuenqa for uploading it:\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"pcuenq/oxford-pets\")\n\nOne of the most important rules of machine learning is to always look at the data. This is quite easy with images, since we can just show the image.\nLet‚Äôs define a helper function to show thumbnails of an image:\n\nimport numpy as np\n\ndef thumbnail(image, scale=3):\n    return image.resize(np.array(image.size)//scale)\n\nHere‚Äôs an example of a cat:\n\ncat_row = dataset['train'][15]\ncat_image = cat_row['image']\nthumbnail(cat_image)\n\n\n\n\n‚Ä¶ and here‚Äôs an example of a dog:\n\ndog_row = dataset['train'][10]\ndog_image = dog_row['image']\nthumbnail(dog_image)\n\n\n\n\n\n\nUsing CLIP for zero-shot classification\nNow that we have a dataset, we can load the CLIP processor and model. The concept of having a separate processor and model is central to the HuggingFace Transformers library, since it allows us to use 174 state-of-the-art models (as of writing this article) with a very similar API.\nNote that it might take a minute to download the pretrained weights:\n\nfrom transformers import CLIPProcessor, CLIPModel\n\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n\nThe CLIPProcessor prepares the inputs for the CLIPModel which can then be used to obtain embedding vectors. Let‚Äôs create a function to embed an image by first passing it through the processor and then into the model:\n\nimport torch\n\ndef embed_image(images):\n    if not isinstance(images, list): images = [images]\n    inputs = processor(images=images, return_tensors=\"pt\", padding=True)\n    with torch.no_grad(): return model.get_image_features(**inputs)\n\nTest that it works:\n\nimages = [cat_image, dog_image]\nimage_embs = embed_image(images)\nimage_embs.shape\n\ntorch.Size([2, 512])\n\n\nYou can also pass text to the CLIPProcessor. Let‚Äôs create a similar function to embed text inputs:\n\ndef embed_text(text):\n    inputs = processor(text=text, return_tensors=\"pt\", padding=True)\n    with torch.no_grad(): return model.get_text_features(**inputs)\n\n\ntext_embs = embed_text([f\"a photo of a {cls}\" for cls in [\"cat\", \"dog\"]])\ntext_embs.shape\n\ntorch.Size([2, 512])\n\n\nWe can now use embeddings for zero-shot classification by using text inputs that represent the different classes, and then calculating the cosine similarity between image embeddings and text embeddings.\nCosine similarity is calculated by taking the dot product of normalized vectors:\n\ndef normalize(a): return a / a.norm(dim=-1, keepdim=True)\ndef cosine_sim(a, b): return normalize(a) @ normalize(b).T\n\n\ncosine_sim(image_embs, text_embs)\n\ntensor([[0.2639, 0.2127],\n        [0.1962, 0.2553]])\n\n\nNote how the similarity between the cat image and the text ‚Äúa photo of a cat‚Äù (0.2639) is higher than the similarity between the cat image and the text ‚Äúa photo of a dog‚Äù (0.2127), and similarly for the dog image in the next row of the tensor.\nWe can convert these similarities to probabilities by using the model‚Äôs logit_scale parameter followed by the softmax method:\n\ndef logits(a, b): return model.logit_scale.exp() * cosine_sim(a, b)\ndef probs(a, b): return logits(a, b).softmax(dim=0)\n\n\nprobs(text_embs, image_embs)\n\ntensor([[0.9940, 0.0027],\n        [0.0060, 0.9973]], grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\nWe see a probability of 0.994 that the image of a cat is in fact a cat, and a probability of 0.997 that the image of a dog is in fact a dog. Pretty good!\nSince this is a zero-shot classifier, we can very easily generalize it to arbitrary classes! Let‚Äôs make a convenient wrapper to do exactly that:\n\ndef classify(image, classes, template=\"a photo of a {}\"):\n    image_embs = embed_image(image)\n    text_embs = embed_text([template.format(o) for o in classes])\n    return probs(text_embs, image_embs)\n\nTo use this, simply pass in a list of classes. You can also customize the template, which can improve the classification accuracy.\nHere‚Äôs how we can classify the breed of a cat:\n\ncat_breeds = sorted({row[\"label\"] for row in dataset[\"train\"] if not row[\"dog\"]})\nscores = classify(cat_image, cat_breeds, \"a photo of a {} cat\")\nscores\n\ntensor([[1.2116e-05],\n        [5.4131e-06],\n        [4.6950e-02],\n        [1.9504e-06],\n        [2.1754e-02],\n        [1.7998e-04],\n        [9.0918e-04],\n        [9.1228e-01],\n        [1.7194e-02],\n        [4.6431e-05],\n        [5.8636e-04],\n        [7.8781e-05]], grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nidx = torch.argmax(scores)\ncat_breeds[idx], scores[idx].item()\n\n('Persian', 0.9122824668884277)\n\n\n‚Ä¶ and here‚Äôs how we can classify the color of any animal:\n\nclasses = [\"black\", \"white\", \"red\", \"green\", \"yellow\", \"blue\", \"brown\", \"orange\", \"pink\", \"purple\", \"grey\"]\nscores = classify(cat_image, classes, \"a photo of a {} animal\")\nidx = torch.argmax(scores)\nclasses[idx], scores[idx].item()\n\n('white', 0.8672362565994263)\n\n\nIt works ‚Äì and it‚Äôs super convenient too!\n\n\nUsing CLIP for text-to-image search\nUsing CLIP for search is not too different from using it for zero-shot classification. In fact, search is even simpler! We don‚Äôt need to calculate probabilities since we ultimately only care about the order of items:\n\ndef search(image_embs, query_embs):\n    sims = cosine_sim(image_embs, query_embs).flatten()\n    indices = sims.argsort(descending=True)\n    return indices, sims[indices]\n\n\nindices, sims = search(image_embs, embed_text(\"a photo of a cat\"))\nindices, sims\n\n(tensor([0, 1]), tensor([0.2639, 0.1962]))\n\n\n\nfor i in indices: display(thumbnail(images[i]))\n\n\n\n\n\n\n\nLet‚Äôs try that with a bigger dataset and some more interesting queries:\nLet‚Äôs embed all of the images. Since this took quite a while on my laptop (19 minutes), it‚Äôs convenient to cache the result to disk so that we don‚Äôt slow down iteration in our notebook:\n\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\n\n\nall_image_embs_path = Path(\"oxford_pets_embeddings.npy\")\nif all_image_embs_path.exists():\n    all_image_embs = torch.tensor(np.load(all_image_embs_path))\nelse:\n    all_image_embs = [embed_image(row['image']) for row in tqdm(dataset['train'])]\n    np.save(all_image_embs_path, embs)\n\n\nall_image_embs.shape\n\ntorch.Size([7390, 512])\n\n\n\ndef search_and_display(image_embs, query_embs, k=3):\n    indices, _ = search(image_embs, query_embs)\n    for i in indices[:k]:\n        image = dataset[\"train\"][i.item()][\"image\"]\n        display(thumbnail(image))\n\n\nsearch_and_display(all_image_embs, embed_text(\"a photo of a white puppey on the grass\"))\n\n\n\n\n\n\n\n\n\n\nAmazing! I wonder how obscure we can get?\n\nsearch_and_display(all_image_embs, embed_text(\"a photo of a fluffy pink cat on a tv\"))\n\n\n\n\n\n\n\n\n\n\nIt always surprises me how well this works! ü§Ø\nAnd once again, it‚Äôs super flexible. For example, all we need to change in order to use an image query is to pass the image‚Äôs embeddings instead of text embeddings!\nLet‚Äôs find the most similar images to our fluffy white persian cat from earlier:\n\nsearch_and_display(all_image_embs, embed_image(cat_image))\n\n\n\n\n\n\n\n\n\n\nNow that we have a working CLIP-based vector search engine, how do we share it with the world?"
  },
  {
    "objectID": "posts/how-to-build-your-own-vector-search-engine.html#part-3-tips-for-deploying-your-search-engine",
    "href": "posts/how-to-build-your-own-vector-search-engine.html#part-3-tips-for-deploying-your-search-engine",
    "title": "How to build your own vector search engine",
    "section": "Part 3: Tips for deploying your search engine",
    "text": "Part 3: Tips for deploying your search engine\nIn this section, I‚Äôll share a few tips that you might find helpful in deploying your own search engine based on my experience with Meepo.\n\nHow Meepo works\nMeepo consists of the following two sub-systems:\n\nData pipeline: A set of scripts responsible for maintaining the data that powers the search engine. This includes scraping, running images through CLIP, and maintaining the data storage components (detailed further below).\nWeb app: A simple search form in front of a CLIP-based search engine (as described in part 2). The app reads from the application database and vector search index (written to by the data pipeline), and renders HTML/CSS to the user.\n\n\nData storage consists of two components that are updated by the data pipeline and then read from by the web app:\n\nApplication database: A typical relational database that contains all of the products in the search catalogue, along with associated metadata.\nVector search index: An index for fast approximate nearest neighbour vector search. I used faiss, although there are other options like hnswlib, as well as more full-featured vector search databases like Milvus, Pinecone, Qdrant, and Weaviate.\n\n\nTech stack\nAs for the specific tech choices, here‚Äôs the full stack powering Meepo:\n\nContrastive language-image pretraining: the deep learning method powering Meepo‚Äôs search.\nFaiss: a fast approximate nearest neighbour vector search index.\nConda: a Python package management system.\nnbdev: a platform for developing software using Jupyter notebooks.\nTailwind CSS: a simpler CSS framework.\nDaisyUI: a component library built on Tailwind CSS.\nSQLite: a light but powerful database engine.\nDjango: a battle-tested Python web framework.\nGunicorn: a Python HTTP server that lets us serve our Django application.\nNginx: a powerful and customizeable web server.\nCron: a job scheduler built into Unix operating systems.\nLinode: a cloud hosting provider.\n\n\n\nInfrastructure\nI developed and tested an MVP locally on a small subset of data. Once I was happy with that, I deployed it to a Linode 4 GB Shared CPU VPS (2 CPUs, 4GB RAM, 80GB storage) costing $24 per month, and subscribed to Linode‚Äôs backup service for an additional $5 per month.\n\n\n\n\n\n\nWhy use a Virtual Private Server(VPS) instead of a modern platform as a service option?\n\n\n\nMost people underestimate how much traffic you can serve from a single low cost VPS!\nPieter Levels, a well-known solopreneur, ran more than 40 of his websites serving over 250 million requests per month from a single VPS.\nMarginalia, an indie search engine that focuses on non-commercial content, casually handled the front page of Hackernews with a single server worth ~$5k of commercial hardware in their living room.\nMy good friend Ashton Hudson took the same approach with Serval, a price tracker for South Africa‚Äôs largest online store, which serves 3000 daily active users and stores 7 million time series data points on low cost servers at a total of ~$45 per month.\n\n\nI totally overestimated how much effort it would take to setup a VPS. It wasn‚Äôt that bad and took a few hours in the end. Here‚Äôs how I went about it. Note that these steps only need to be carried out once per server:\n\nRent a VPS: There are plenty of options available. I chose Linode for no particular reason.\nSetup your VPS: This includes updating packages, setting the timezone and hostname, creating a limited user, and tightening SSH settings. I followed this Linode guide.\nSetup nginx: I followed this Real Python guide.\n\nOnce your server is setup, you‚Äôll need to follow a few more setups for your app (and each future app you create):\n\nSetup Gunicorn: I followed the same Real Python guide from above.\nSetup your domain name: Buy a domain name and configure your VPS to use it. I searched for the cheapest name containing ‚Äúmeepo‚Äù and was lucky to score meepo.shop at $2!\nDeploy your web app: I followed Django‚Äôs official deployment guide.\nDeploy your pipeline: I kept it simple and added a crontab entry to a single shell script.\n\n\n\n\nChoosing boring tech\nYou might have noticed that I chose a ‚Äúboring‚Äù tech stack. I believe that boring tech is a key part of what allowed me to ship Meepo so quickly. Let me explain.\n\nIt‚Äôs boring because it works\nIt‚Äôs been around for decades. If that‚Äôs the case, and it‚Äôs still widely used, then it probably works! It might not be the most elegant solution, but it gets the job done. Software that‚Äôs been maintained for a long time is software that‚Äôs been hardened against many thousands of obscure edge-cases that users like you and I no longer have to worry about.\nFor example, Meepo is a Django application, and Django is 20 years old. That‚Äôs 20 years of incremental improvements and bug fixes resulting in a truly robust piece of software.\n\n\nInnovate on your process, not only your tech\nDevelopers typically enjoy learning new tools. That‚Äôs a good thing, but it also means that we‚Äôre biased to choosing new tools even when they aren‚Äôt necessarily improvements over the status quo.\nInstead of focusing on learning a new tool, try focusing on mastering tools you already know, and developing excellent decision-making skills on top of those tools with a ruthless focus on shipping quickly.\nFor me, this meant using Django instead of something like FastAPI, and using a simple Linux VPS instead of a more modern platform as a service option. But this is different for everyone and depends on each person‚Äôs individual experience.\n\n\nDeviating from what works\nOf course, absolute rules are rarely a good idea in any domain as complex as software. There are definitely cases where less boring tech can be a good idea ‚Äì I try to have a very specific reason before deviating from my favorite boring tools.\nFor example, I developed Meepo entirely in Jupyter notebooks. It sounds crazy, I know! But there‚Äôs something about notebook-driven development that I can‚Äôt quite shake. It makes programming feel like a game. There‚Äôs constant feedback, very quick iteration cycles, and everything is within reach: code, rich docs, and tests all in one place. In fact, the second part of this post was based on the same notebooks that run Meepo.\n\n\n\nBeing a responsible digital citizen\nIf I‚Äôm scraping a website, I‚Äôm most likely not the website‚Äôs intended audience, so I try very hard not to negatively impact the user experience of their intended audience.\nLegal concerns around web scraping are pretty vague. However, as long as you provide value to the underlying service, they probably won‚Äôt mind you scraping them. For example, nobody cares that Google scrapes their sites because they provide traffic via search. Similarly, fashion stores that Meepo scrapes probably won‚Äôt mind the extra traffic it brings them.\nHere are some more detailed tips for scraping responsibly:\n\nCheck how big the viewership of the website is. I would personally be hesitant to scrape a small website and would probably prefer to email the owner directly.\nIdentify yourself with contact information via the user agent header ‚Äì don‚Äôt try to fake being a human! A simple pattern you can use is¬†your.website.com/x.y (your@email.com)¬†where¬†x.y¬†is your scraper‚Äôs version number.\nBe considerate about their resource usage, especially since you aren‚Äôt their intended audience.\nDo the bulk of your requests during off-peak times depending on the local timezone of their audience.\nSleep between requests as much as you possibly can. Add small random amounts as well to reduce the likelihood of overlapping with other scheduled scrapers and bots, thus reducing peak load.\nUse compression when scraping plain text or JSON to minimise their outgoing traffic. It doesn‚Äôt work nearly as well for images so it‚Äôs probably best to not compress them to avoid extra CPU usage on their servers."
  },
  {
    "objectID": "posts/how-to-build-your-own-vector-search-engine.html#your-turn",
    "href": "posts/how-to-build-your-own-vector-search-engine.html#your-turn",
    "title": "How to build your own vector search engine",
    "section": "Your turn",
    "text": "Your turn\nNow it‚Äôs your turn. Dive into the accompanying notebook for this post, give it a try with your own dataset, deploy the result, and share what you create!\nIf you found this enjoyable, consider giving it a thumbs up below, commenting, and following me at @wasimlorgat on Twitter. The positive feedback really helps me get a sense of what readers find valuable!\n\nMany thanks to Kurian Benoy, Jeremy Howard, Pedro Cuenca, and Salman Naqvi, for their kind and thoughtful comments on various versions of this post."
  },
  {
    "objectID": "posts/doing-important-work.html",
    "href": "posts/doing-important-work.html",
    "title": "Doing important work",
    "section": "",
    "text": "I‚Äôve been thinking a lot about what it means to Do Important Work, and there two quotes in particular that have stuck with me.\nThe first is from Visa‚Äôs The Prestige Trap. With his classic wit and charm, Visa breaks the problem down in the opening sentence:\n\nI‚Äôve had several conversations with friends who‚Äôve been incapacitated by the burdensome bullshit obligation to Have A Meaningful Life / Be Remembered / Do Important Work.\n\nAnd though the details differ, the second is a tweet from Michael Nielsen that I think is closely related:\n\nI try particularly to push back on the efficiency mindset with work (where it‚Äôs strongest). Asking ‚ÄúWhat‚Äôs a much more enjoyable way‚Äù to achieve some outcome (even if inefficient) has been very good for me. Amusingly, though not the point, it often makes the work much better too\n\nI think they‚Äôre very much speaking about the same thing. Many of us want to Do Important Work, including, in my opinion, Michael and Visa. That‚Äôs fine. A natural follow-up is to try to make it concrete with a question: What important work can I do?\nBut here‚Äôs the problem. Measuring the importance or meaning of an action is really hard. I‚Äôm not sure it‚Äôs even possible. From a pragmatic perspective, we might say that important work is recognised through reward, perhaps monetary. But, as Visa reminds us, ‚Äònobody really knows what the world needs! The world itself doesn‚Äôt quite know either, often until on hindsight!‚Äô.\nSo what do we do instead? Well, what seems to have worked empirically is to ‚Äòenjoy the piddling‚Äô. To be playful and curious. To prefer the more enjoyable way. Feynman, Jobs, Wozniak, and Newton are all examples cited by Visa. It‚Äôs okay to want to Do Important Work. I think both Michael and Visakan really do want that. And I know I do. The trick is to rejig the way that you think about it away from the destructive default to a more constructive, and amusingly efficient alternative. I‚Äôm delighted by the similarity between Visa‚Äôs and Michael‚Äôs descriptions:\n\nVisa: Wonderfully, it seems to me that lots of people who end up Doing Important Work often got there by being playful and curious.\n\n\nMichael: Amusingly, though not the point, it often makes the work much better too.\n\nIt really is both wonderful and amusing. It feels like the gist of a koan: to Do Important Work, you must forget about Doing Important Work."
  },
  {
    "objectID": "posts/jupytercon-2023.html",
    "href": "posts/jupytercon-2023.html",
    "title": "Write, document, test and distribute Python packages with nbdev & Quarto",
    "section": "",
    "text": "I attended JupyterCon 2023 in Paris two weeks ago. On Thursday, Hamel Husain, myself, and J. J. Allaire (as a teaching assistant) presented a two and a half hour tutorial on Writing, Documenting, Testing, and Distributing Python Packages with nbdev and Quarto.\nI think it went well! The room was full and attendees engaged with great questions.\n\n\n\nScreenshot of the tutorial website taken with shot-scraper.\n\n\nHamel opened by describing the roots of nbdev‚Äôs programming paradigm: a combination of literate programming (introduced by Donald Knuth) and exploratory programming (beautifully demonstrated by Bret Victor) made possible by Jupyter notebooks. He then took us through both basic and advanced usage of Quarto ‚Äì the publishing platform that powers nbdev‚Äôs documentation generation.\nI followed with a demonstration of how I do notebook-driven development by live coding the now classic nbdev example: a library for interacting with playing cards based on Chapter 18 of Allen B. Downey‚Äôs Think Python. I tried to focus on the thinking process and how it differs from more conventional programming paradigms, rather than focusing on the mechanics of how nbdev works since that is so readily available online.\nMy demonstration was largely based on the official written nbdev tutorial and best practices post. I also used the tutorial as an opportunity to refine these docs. The biggest refinement was that I now recommend JupyterLab instead of the classic notebook. There are two main reasons for this:\n\nLab has a growing extension ecosystem:\n\nI can‚Äôt live without the wonderful jupyterlab-quarto. It renders Quarto markdown including frontmatter, callouts, and fenced divs which greatly improves the authoring experience.\nThere is interesting work being done on LLM-related extensions like jupyter-ai which adds an LLM chat interface to the sidebar.\n\nLab 4.0.0 was released! It comes with significantly better performance among a ton of other improvements. Most notably for me is a built-in implementation of classic‚Äôs collapsible headings extension (including the keyboard shortcuts). However, it is worth noting that extensions will need to migrate to version 4 and I‚Äôm not sure what this process will look like!\n\nYou can also find an outline of the tutorial as well as the slides for Hamel‚Äôs opening section at the tutorial website: https://fastai.github.io/jupytercon-2023.\nBy the way, we wrote the tutorial site using Quarto too! Here is the underlying repo: https://github.com/fastai/jupytercon-2023.\nThe conference venue was beautiful! On the last day, David Brochart, Hamel Husain, and I took a walk around the Cit√© des sciences et de l‚Äôindustrie and surrounding area, and David shared some of the fascinating history behind the city.\n\n\n\nDavid Brochart, Hamel Husain, and myself pictured in front of the Philharmonie de Paris a short walk away from the JupyterCon 2023 conference hall."
  },
  {
    "objectID": "posts/code-neq-idea.html",
    "href": "posts/code-neq-idea.html",
    "title": "Code != idea",
    "section": "",
    "text": "(The original title and description of the talk changed between the pitch and final version, hence the differences.)\nThis is a lightning talk I gave at the satRday 2018 conference. In it, I share an epiphany I had about programming and how it relates to people and our ideas, after programming for most of my life and discovering higher-level languages like Python and R. The talk won best student lightning talk, which included a copy of the beautiful R for Data Science signed by Hadley Wickham himself!\nFast forward 4 years, and this realisation doesn‚Äôt feel as profound as it once did, but that‚Äôs okay. I believe the world would be a little better if everyone shared their personal learnings and experiences. Please let me know of yours!\nAnyway, keep scrolling for a written version of the talk."
  },
  {
    "objectID": "posts/code-neq-idea.html#my-journey-from-game-maker-to-python",
    "href": "posts/code-neq-idea.html#my-journey-from-game-maker-to-python",
    "title": "Code != idea",
    "section": "My journey from Game Maker to Python ",
    "text": "My journey from Game Maker to Python \n\n\n\n\n\nGood morning everyone, my name is Wasim.\nA little background. I started programming when I was in primary school. I‚Äôve always loved games, and making things. Unsurprisingly, my foray into programming started with making games.\nAfter vigorous searching for game making software, with my favourite search engine at the time, AltaVista, which some of you may remember, I found a program called Game Maker.\nIt had a GUI, where you created game objects and programmed logic into them with buttons. It also had scripting capabilities. But I didn‚Äôt dare to delve into them.\n\n\n\n\n\nEventually, a cousin of mine introduced me to a more powerful tool. A programming language called DarkBASIC, a form of the language, BASIC.\nIt had a nice editor, a built-in command line interface. I think the 1 and 2 on the top right corresponded to tabs. And it allowed you to create 3D games.\n\n\n\n\n\nI then moved on to some of the more ‚Äúreal‚Äù programming languages. I dabbled in C++.\nI was taught Java in high school.\nAnd finally, I settled on Python. I think the reason I hopped so often from one language to the next, was because I was never quite satisfied with how it ‚Äúfelt‚Äù to program in these languages. I was never truly comfortable with the way I had to translate what I thought into what I typed. Until Python."
  },
  {
    "objectID": "posts/code-neq-idea.html#the-joy-of-high-level-languages",
    "href": "posts/code-neq-idea.html#the-joy-of-high-level-languages",
    "title": "Code != idea",
    "section": "The joy of high-level languages ",
    "text": "The joy of high-level languages \n\n\n\n\n\nWith Python, I learned about writing and reading beautiful code. If you haven‚Äôt already seen this poem, The Zen of Python, by Tim Peters, you should check it out.\nThere is an idea called writing ‚ÄúPythonic‚Äù code, which this poem sort of defines. There was something compelling, almost poetic, about reading and writing ‚ÄúPythonic‚Äù code.\nAs a young programmer, it was the first time I realized the importance of how code looks, not just what it does."
  },
  {
    "objectID": "posts/code-neq-idea.html#this-is-not-a-pipe",
    "href": "posts/code-neq-idea.html#this-is-not-a-pipe",
    "title": "Code != idea",
    "section": "This is not a pipe ",
    "text": "This is not a pipe \n\n\n\n\n\nMore recently, I came across an even more interesting idea about how code looks.\nHere‚Äôs a painting, by the French artist, Ren√© Magritte, that captures the idea. The text at the bottom translates to ‚ÄúThis is not a pipe.‚Äù\nIf you haven‚Äôt seen this before, that might be a little confusing.\n‚ÄúThat is a pipe. I‚Äôve seen pipes before, and that, my friend, is a pipe.‚Äù\nWell, you can‚Äôt pack this with tobacco and smoke it. This is a painting of a pipe, an image, a representation, but its not the pipe itself.\nAt this point, you might be wondering: What does this have to do with code? And what does this talk have to do with R?\nWell, just as this is a representation of a pipe‚Ä¶"
  },
  {
    "objectID": "posts/code-neq-idea.html#this-is-not-an-idea",
    "href": "posts/code-neq-idea.html#this-is-not-an-idea",
    "title": "Code != idea",
    "section": "This is not an idea ",
    "text": "This is not an idea \n\n\n\n\n\nThis is a representation of an idea. The code is not the idea itself.\nI believe that when we code (even for experts) we constantly struggle translating between our idea and its representation. If the code is a particularly good representation of our underlying idea, then it flows seamlessly, almost by itself.\nOn the other hand, if the code is not a good representation of our idea, then this struggle is quite costly.\nI wanna show you, by example, why I‚Äôm so fascinated by R. This is some very simple dplyr code.\nWhat I do when I read (or write) code like this, is to translate it to and from English. I don‚Äôt think ‚Äúdf percent greater than percent‚Ä¶‚Äù"
  },
  {
    "objectID": "posts/code-neq-idea.html#translating-code-to-idea",
    "href": "posts/code-neq-idea.html#translating-code-to-idea",
    "title": "Code != idea",
    "section": "Translating code to idea ",
    "text": "Translating code to idea \n\nI might start off by thinking that I want to ‚ÄúTake df‚Äù, in order to do something to it.\nI‚Äôd read the pipe symbol %&gt;% as ‚Äúthen‚Äù.\nI then want to filter ‚Äúrows of df where‚Äù\nRead the symbol as ‚Äúis less than‚Äù\nReplace the pipe symbol with ‚Äúthen‚Äù again\nI then want to arrange rows of df by‚Ä¶\nSame thing with the pipe symbol.\nAnd finally, I want to select the column‚Ä¶\nAnd, very easily, we have an English sentence.\nOh! And if we‚Äôre really fussy, we could add punctuation.\nSo we‚Äôve translated, very easily and systematically, from dplyr code to English.\nIsn‚Äôt that a beautiful representation?\nIt‚Äôs beautiful because it‚Äôs been so carefully designed, functions have been so carefully named, all keeping in mind one very important principle:"
  },
  {
    "objectID": "posts/code-neq-idea.html#code-represents-the-ideas-of-people",
    "href": "posts/code-neq-idea.html#code-represents-the-ideas-of-people",
    "title": "Code != idea",
    "section": "Code represents the ideas of people ",
    "text": "Code represents the ideas of people \n\n\n\n\n\nCode represents the ideas of people. By considering the people who will use it, we minimize the cost of translating from obscure machine-friendly commands into beautiful prose.\nAnd by minimizing this cost, it frees our minds to focus on what‚Äôs really important: the ideas themselves."
  },
  {
    "objectID": "posts/how-to-build-your-own-minimal-jupyter-frontend.html",
    "href": "posts/how-to-build-your-own-minimal-jupyter-frontend.html",
    "title": "How to build your own minimal Jupyter frontend",
    "section": "",
    "text": "Photo by Planet Volumes on Unsplash\nThis blog post (and the source notebook) is an executable playground for understanding how to communicate with Jupyter Servers. You can think of it as a barebones Jupyter frontend, since we‚Äôll be implementing the full lifecycle including creating a new notebook, writing and executing code cells, and shutting down the server.\nI‚Äôm building my own native macOS Jupyter frontend and writing about my experience and learnings along the way. In order to do that, I need to be familiar with how Jupyter Servers works.\nMy approach to learning this was a combination of using Chrome dev tools to inspect network requests in Jupyter Lab, and reading the wonderful Jupyter Server docs (particularly the REST API reference). I‚Äôll include links to the relevant docs in each section below.\nLet‚Äôs get started!"
  },
  {
    "objectID": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#starting-the-server",
    "href": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#starting-the-server",
    "title": "How to build your own minimal Jupyter frontend",
    "section": "Starting the server",
    "text": "Starting the server\nTo start, ensure that you‚Äôre running a Jupyter Server in another process (e.g.¬†in a terminal) by entering the following command:\njupyter server\nOnce the server is running, update the url_with_token variable below to match what‚Äôs displayed in the terminal output. For example, it should output something like this:\n[C 2023-01-07 12:03:57.482 ServerApp]\n\n    To access the server, open this file in a browser:\n        file:///Users/seem/Library/Jupyter/runtime/jpserver-80287-open.html\n    Or copy and paste one of these URLs:\n        http://localhost:8889/?token=72b22f0cee26baaa6aed492b6fed5a010d57bd6c0e1adcce\n     or http://127.0.0.1:8889/?token=72b22f0cee26baaa6aed492b6fed5a010d57bd6c0e1adcce\n\n# NB: Update this based on your terminal output\nurl_with_token = 'http://localhost:8889/?token=e78ceb3114cb10d50f64485b18e3052c66861616166e0bab'"
  },
  {
    "objectID": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#authenticating",
    "href": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#authenticating",
    "title": "How to build your own minimal Jupyter frontend",
    "section": "Authenticating",
    "text": "Authenticating\nFirst, we‚Äôll do a quick check that there is a server at the defined url. We need to get the URL without the token query parameter:\n\nfrom urllib.parse import urlparse\n\n\nurl = urlparse(url_with_token)._replace(query=None).geturl()\nurl\n\n'http://localhost:8889/'\n\n\nNow we can make the request:\n\nimport requests\n\n\nrequests.get(url)\n\n&lt;Response [200]&gt;\n\n\nA 200 response means that the server processed the request successfully.\nNext we need to authenticate. What happens if we try to make a request to an endpoint that requires authentication, for example GET /api/contents?\n\nrequests.get(url + 'api/contents')\n\n&lt;Response [403]&gt;\n\n\nIt fails with 403 Forbidden.\nIf we include our token in the Authorization header:\n\ntoken = urlparse(url_with_token).query.split('=')[-1]\nheaders = {'Authorization': f'token {token}'}\nrequests.get(url + 'api/contents', headers=headers)\n\n&lt;Response [200]&gt;\n\n\n‚Ä¶ it works!\nLet‚Äôs create a requests.Session so we don‚Äôt have to keep specifying the header:\n\nsession = requests.Session()\nsession.headers.update(headers)"
  },
  {
    "objectID": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#managing-files",
    "href": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#managing-files",
    "title": "How to build your own minimal Jupyter frontend",
    "section": "Managing files",
    "text": "Managing files\nJupyter Server lets you manage files via the Contents API. Browser frontends access this via the /api/contents REST API.\nLet‚Äôs use the Contents API to create a file, rename it, and write some contents to it.\n\nList the contents of a directory\nGET /api/contents/&lt;path&gt; returns the contents of the file or directory at path. You can think of it as ls for Jupyter Server:\n\nsession.get(url + 'api/contents').json()\n\n{'name': '',\n 'path': '',\n 'last_modified': '2023-01-19T05:58:38.693411Z',\n 'created': '2023-01-19T05:58:38.693411Z',\n 'content': [],\n 'format': 'json',\n 'mimetype': None,\n 'size': None,\n 'writable': True,\n 'type': 'directory'}\n\n\nSince the directory is currently empty, content is an empty list.\n\n\nCreate an empty notebook\nPOST /api/contents/&lt;path&gt; creates an empty file in the directory at path. You can specify the type of the file in the request body:\n\nsession.post(url + 'api/contents', json={'type': 'notebook'})\n\n&lt;Response [201]&gt;\n\n\nThe 201 status code means that the request succeeded and a resource was created.\nLet‚Äôs confirm that the file exists with GET /api/contents:\n\nsession.get(url + 'api/contents').json()\n\n{'name': '',\n 'path': '',\n 'last_modified': '2023-01-19T06:01:01.089699Z',\n 'created': '2023-01-19T06:01:01.089699Z',\n 'content': [{'name': 'Untitled.ipynb',\n   'path': 'Untitled.ipynb',\n   'last_modified': '2023-01-19T06:01:01.090600Z',\n   'created': '2023-01-19T06:01:01.090600Z',\n   'content': None,\n   'format': None,\n   'mimetype': None,\n   'size': 72,\n   'writable': True,\n   'type': 'notebook'}],\n 'format': 'json',\n 'mimetype': None,\n 'size': None,\n 'writable': True,\n 'type': 'directory'}\n\n\nThe response is a nested dict. The root dict refers to the root directory as before, however, content now contains the newly created notebook named Untitled.ipynb.\nWe can get the contents of this file using the same method but referring to the file‚Äôs path i.e.¬†GET /api/contents/&lt;path&gt;:\n\ndata = session.get(url + 'api/contents/Untitled.ipynb').json()\ndata\n\n{'name': 'Untitled.ipynb',\n 'path': 'Untitled.ipynb',\n 'last_modified': '2023-01-19T06:01:01.090600Z',\n 'created': '2023-01-19T06:01:01.090600Z',\n 'content': {'cells': [], 'metadata': {}, 'nbformat': 4, 'nbformat_minor': 5},\n 'format': 'json',\n 'mimetype': None,\n 'size': 72,\n 'writable': True,\n 'type': 'notebook'}\n\n\nWe‚Äôre probably most interested in content, which contains the JSON content of the notebook:\n\ndata['content']\n\n{'cells': [], 'metadata': {}, 'nbformat': 4, 'nbformat_minor': 5}\n\n\nFor now, the notebook only has some metadata, and cells is empty.\n\n\nRename a notebook\nOur newly created file is still named Untitled.ipynb. Let‚Äôs rename it to sum.ipynb with PATCH /api/contents/&lt;path&gt;:\n\nsession.patch(url + 'api/contents/Untitled.ipynb', json={'path': 'sum.ipynb'}).json()\n\n{'name': 'sum.ipynb',\n 'path': 'sum.ipynb',\n 'last_modified': '2023-01-19T06:01:01.090600Z',\n 'created': '2023-01-19T06:01:01.210202Z',\n 'content': None,\n 'format': None,\n 'mimetype': None,\n 'size': 72,\n 'writable': True,\n 'type': 'notebook'}\n\n\nConfirm that it‚Äôs been renamed. Untitled.ipynb no longer exists:\n\nsession.get(url + 'api/contents/Untitled.ipynb').json()\n\n{'message': 'No such file or directory: Untitled.ipynb', 'reason': None}\n\n\n‚Ä¶ but sum.ipynb does:\n\nsession.get(url + 'api/contents/sum.ipynb').json()\n\n{'name': 'sum.ipynb',\n 'path': 'sum.ipynb',\n 'last_modified': '2023-01-19T06:01:01.090600Z',\n 'created': '2023-01-19T06:01:01.210202Z',\n 'content': {'cells': [], 'metadata': {}, 'nbformat': 4, 'nbformat_minor': 5},\n 'format': 'json',\n 'mimetype': None,\n 'size': 72,\n 'writable': True,\n 'type': 'notebook'}\n\n\n\n\n\n\n\n\n\n\n\n\nYou can also create a file with a specified name using PUT /api/contents/&lt;path&gt;, instead of letting the server find a unique named prefixed with Untitled.\n\n\n\n\nUpdate a notebook‚Äôs contents\nCreate a cell and append it to existing contents:\n\ncell = {\n    'cell_type': 'code',\n    'id': '0',\n    'metadata': {},\n    'source': [\n        '1 + 1\\n',\n    ],\n    'outputs': [],\n    'execution_count': 0,\n}\ndata = session.get(url + 'api/contents/sum.ipynb').json()\ndata['content']['cells'].append(cell)\n\nUpdate the notebook‚Äôs contents using PUT /api/contents/&lt;path&gt;:\n\nsession.put(url + 'api/contents/sum.ipynb', json={'content': data['content'], 'type': 'notebook'})\n\n&lt;Response [200]&gt;\n\n\nConfirm that the notebook‚Äôs been updated. Note that last_modified and content have both updated:\n\nsession.get(url + 'api/contents/sum.ipynb').json()\n\n{'name': 'sum.ipynb',\n 'path': 'sum.ipynb',\n 'last_modified': '2023-01-19T06:01:01.348274Z',\n 'created': '2023-01-19T06:01:01.348274Z',\n 'content': {'cells': [{'cell_type': 'code',\n    'execution_count': 0,\n    'id': '0',\n    'metadata': {'trusted': True},\n    'outputs': [],\n    'source': '1 + 1\\n'}],\n  'metadata': {},\n  'nbformat': 4,\n  'nbformat_minor': 5},\n 'format': 'json',\n 'mimetype': None,\n 'size': 216,\n 'writable': True,\n 'type': 'notebook'}"
  },
  {
    "objectID": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#executing-code",
    "href": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#executing-code",
    "title": "How to build your own minimal Jupyter frontend",
    "section": "Executing code",
    "text": "Executing code\nMost of the functionality available inside a Jupyter Notebook in your browser is achieved by communicating with the server via websockets. This includes executing code as well as code completion.\nLet‚Äôs execute a very simple bit of code on the server.\n\nStart a session\nList open sessions with GET /api/sessions:\n\nsession.get(url + 'api/sessions').json()\n\n[]\n\n\nFirst we need to choose a kernel specification. Here are the available options on my computer ‚Äì yours will likely differ:\n\nsession.get(url + 'api/kernelspecs').json()\n\n{'default': 'python3',\n 'kernelspecs': {'dyalog-kernel': {'name': 'dyalog-kernel',\n   'spec': {'argv': ['python3',\n     '-m',\n     'dyalog_kernel',\n     '-f',\n     '{connection_file}'],\n    'env': {},\n    'display_name': 'Dyalog APL',\n    'language': 'apl',\n    'interrupt_mode': 'signal',\n    'metadata': {}},\n   'resources': {'kernel.js': '/kernelspecs/dyalog-kernel/kernel.js'}},\n  'python3': {'name': 'python3',\n   'spec': {'argv': ['python',\n     '-m',\n     'ipykernel_launcher',\n     '-f',\n     '{connection_file}'],\n    'env': {},\n    'display_name': 'Python 3 (ipykernel)',\n    'language': 'python',\n    'interrupt_mode': 'signal',\n    'metadata': {'debugger': True}},\n   'resources': {'logo-64x64': '/kernelspecs/python3/logo-64x64.png',\n    'logo-32x32': '/kernelspecs/python3/logo-32x32.png',\n    'logo-svg': '/kernelspecs/python3/logo-svg.svg'}}}}\n\n\nCreate a new session with POST /api/sessions with the python3 kernelspec:\n\ndata = session.post(url + 'api/sessions', json={'kernel': {'name': 'python3'}, 'name': 'sum.ipynb', 'path': 'sum.ipynb', 'type': 'notebook'}).json()\ndata\n\n{'id': '5730d780-fa1f-446e-b8ad-f3e66be9d063',\n 'path': 'sum.ipynb',\n 'name': 'sum.ipynb',\n 'type': 'notebook',\n 'kernel': {'id': '760db402-af7f-4559-aa39-5518d2107b14',\n  'name': 'python3',\n  'last_activity': '2023-01-19T06:01:01.734770Z',\n  'execution_state': 'starting',\n  'connections': 0},\n 'notebook': {'path': 'sum.ipynb', 'name': 'sum.ipynb'}}\n\n\nNow that a session exists, we can connect to a websocket. We‚Äôll need the kernel_id and session_id to do that, so let‚Äôs store them for the next step:\n\nkernel_id = data['kernel']['id']\nsession_id = data['id']\n\n\n\nCommunicate over WebSockets\nFirst, let‚Äôs craft a message to request an execution ‚Äì you can try changing the value of the code variable below to execute something else:\n\nimport uuid\n\ncode = '1 + 1'\ncode_msg_id = str(uuid.uuid1())\ncode_msg = {'channel': 'shell',\n            'content': {'silent': False, 'code': code},\n            'header': {'msg_id': code_msg_id, 'msg_type':'execute_request'},\n            'metadata': {},\n            'parent_header':{}}\n\nNow we can send the message to the server and receive all responses.\nWe‚Äôll use the websocket-client library. You might also want to consider the websockets library which is asynchronous.\n\nimport json\nfrom contextlib import closing\nfrom websocket import create_connection, WebSocketTimeoutException\n\ndef recv_all(conn):\n    while True:\n        try: msg = json.loads(conn.recv())\n        except WebSocketTimeoutException: break\n        print(f\"  type: {msg['msg_type']:16} content: {msg['content']}\")\n\nws_base_url = urlparse(url)._replace(scheme='ws').geturl()\nws_url = ws_base_url + f'api/kernels/{kernel_id}/channels?session_id={session_id}'\n\nwith closing(create_connection(ws_url, header=headers, timeout=1)) as conn:\n    print('Receiving initial messages\\n')\n    recv_all(conn)\n    print('\\nSending execute_request\\n')\n    conn.send(json.dumps(code_msg))\n    print('Receiving execute_reply\\n')\n    recv_all(conn)\n\nReceiving initial messages\n\n  type: status           content: {'execution_state': 'busy'}\n  type: status           content: {'execution_state': 'idle'}\n  type: status           content: {'execution_state': 'idle'}\n\nSending execute_request\n\nReceiving execute_reply\n\n  type: status           content: {'execution_state': 'busy'}\n  type: execute_input    content: {'code': '1 + 1', 'execution_count': 1}\n  type: execute_result   content: {'data': {'text/plain': '2'}, 'metadata': {}, 'execution_count': 1}\n  type: status           content: {'execution_state': 'idle'}\n  type: execute_reply    content: {'status': 'ok', 'execution_count': 1, 'user_expressions': {}, 'payload': []}\n\n\nYay! We successfully executed code on the server via websockets.\nYou can learn more about Jupyter‚Äôs messaging specification in the Jupyter Client docs."
  },
  {
    "objectID": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#cleanup",
    "href": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#cleanup",
    "title": "How to build your own minimal Jupyter frontend",
    "section": "Cleanup",
    "text": "Cleanup\nIt‚Äôs always good practice to cleanup after ourselves, particularly if we share the server with other users.\nLet‚Äôs close our session and shutdown the server (although we probably wouldn‚Äôt shut it down if we shared it with others!).\n\nClose the session\nSince we‚Äôre done with the session, we can close it via DELETE /api/sessions/&lt;session_id&gt;:\n\nsession.delete(url + f'api/sessions/{session_id}')\n\n&lt;Response [204]&gt;\n\n\n\n\nShutdown the server\nFinally, shutdown the server via POST /api/shutdown.\n\nsession.post(url + 'api/shutdown')\n\n&lt;Response [200]&gt;\n\n\n‚Ä¶ and confirm that it‚Äôs been shutdown correctly:\n\ntry: session.get(url)\nexcept requests.exceptions.ConnectionError: print('Server has been successfully shutdown!')\n\nServer has been successfully shutdown!\n\n\nAll done!"
  },
  {
    "objectID": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#next-steps",
    "href": "posts/how-to-build-your-own-minimal-jupyter-frontend.html#next-steps",
    "title": "How to build your own minimal Jupyter frontend",
    "section": "Next steps",
    "text": "Next steps\nCongrats! If you followed all the way to the end, you‚Äôve now created a barebones Jupyter frontend. Here are some directions you might consider to take this further:\n\nHow would you implement other notebook features like code completion?\nHow does Jupyter‚Äôs trust system work?\nHow would you implement Jupyter‚Äôs checkpointing system?\nCan you redo this in another language?\nHow would you design and build your own UI on top of this?\n\nAs for me, my next step is to start translating these into Swift as part of the native macOS Jupyter frontend I‚Äôm building.\nLet me know on Twitter or via email if you enjoyed this or if you have any questions!"
  },
  {
    "objectID": "posts/math-of-diffusion.html",
    "href": "posts/math-of-diffusion.html",
    "title": "Understand the math of diffusion without a PhD",
    "section": "",
    "text": "Check out Lesson 9B: Math of Diffusion of fast.ai‚Äôs Practical Deep Learning for Coders Part 2, 2022 from the wonderful Tanishq and myself if you want to understand the math of diffusion but feel intimidated by the jargon. You‚Äôll learn about the key equations underpinning diffusion models, with no prerequisites beyond high school math."
  },
  {
    "objectID": "posts/math-of-diffusion.html#what-youll-learn",
    "href": "posts/math-of-diffusion.html#what-youll-learn",
    "title": "Understand the math of diffusion without a PhD",
    "section": "What you‚Äôll learn",
    "text": "What you‚Äôll learn\nWe walk through the math of diffusion models from the ground up, explaining the insights underlying the key equations in the work of Sohl-Dickstein et al. (2015) that originally discovered diffusion models.\nBy the end of the lesson you‚Äôll have some understanding of the following key concepts and you‚Äôll know how to recognize and interpret their symbols in research papers: probability density function (pdf), data distribution, forward process, reverse process, Markov process, Gaussian distribution, log likelihood, and evidence lower bound (ELBO).\nWe also touch on the more recent breakthroughs of Ho, Jain, and Abbeel (2020) which enabled even simpler and more powerful diffusion models.\nYou can discuss this lesson, and access links to all notebooks and resources from it, at this forum topic."
  },
  {
    "objectID": "posts/math-of-diffusion.html#you-dont-need-a-phd",
    "href": "posts/math-of-diffusion.html#you-dont-need-a-phd",
    "title": "Understand the math of diffusion without a PhD",
    "section": "You don‚Äôt need a PhD",
    "text": "You don‚Äôt need a PhD\nHere‚Äôs what Alex, a student of the course, had to say about the lesson:\n\n\n\n\n\nYou definitely don‚Äôt need a PhD! In fact, the lesson came about because I felt the same way as Alex. I was frustrated at how difficult I found it to understand the math in diffusion papers."
  },
  {
    "objectID": "posts/math-of-diffusion.html#recorded-at-fast.ai-hq",
    "href": "posts/math-of-diffusion.html#recorded-at-fast.ai-hq",
    "title": "Understand the math of diffusion without a PhD",
    "section": "Recorded at fast.ai HQ",
    "text": "Recorded at fast.ai HQ\nThanks to nudges from Jeremy, we went from an informal conversation, to a talk at the fast.ai unconference, to a recorded lesson ‚Äì in a span of 4 days! Jeremy was kind enough to let us use his equipment and record at the fast.ai HQ."
  },
  {
    "objectID": "posts/math-of-diffusion.html#check-out-the-other-lesson-resources",
    "href": "posts/math-of-diffusion.html#check-out-the-other-lesson-resources",
    "title": "Understand the math of diffusion without a PhD",
    "section": "Check out the other lesson resources",
    "text": "Check out the other lesson resources\nI‚Äôm grateful to be part of this amazing group of people developing fast.ai‚Äôs From Deep Learning Foundations to Stable Diffusion. Follow the tweet below to find more lesson resources from the team: Johno Whitaker, Pedro Cuenca, Tanishq Abraham, and of course Jeremy Howard.\n\n\nI got a special surprise for you all‚Ä¶We just released the first 5.5 hours of our new course \"From Deep Learning Foundations to Stable Diffusion\", for free!https://t.co/LiUu9HSflG\n\n‚Äî Jeremy Howard ((jeremyphoward?)) October 20, 2022"
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html",
    "href": "posts/fastai-array-programming-day-1.html",
    "title": "Notes from the fast.ai APL study group",
    "section": "",
    "text": "Here are my notes for day 1 of the FastAI array programming study group run by Jeremy Howard. Check out the official thread on the FastAI forum for up-to-date info. Any mistakes are mine - please let me know if you spot one."
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html#why-learn-apl",
    "href": "posts/fastai-array-programming-day-1.html#why-learn-apl",
    "title": "Notes from the fast.ai APL study group",
    "section": "Why learn APL?",
    "text": "Why learn APL?\n[Jeremy gave a personal answer here. I‚Äôve paraphrased here and there, and reframed it in the third person, hopefully without changing his intended meaning.]\n\nAPL is a way into learning and teaching math\nMath is beautiful‚Ä¶ but also very frustrating. It‚Äôs inconsistent, the notation is hard to lookup, and it‚Äôs hard to understand what things mean in a very abstract way when we can‚Äôt experiment with them. APL helps us understand math, thus it helps us teach math.\nJeremy teaches his daughter and her friend math. He found that there were concepts that he found very difficult to teach in traditional abstract ways. In particular, he spent an hour trying to teach them sequences and series with very little progress. He then tried it again with numpy and APL and it clicked much more easily.\n\n\nThere‚Äôs emmense beauty and power in notations\nIn a previous live coding session, Jeremy talked about regex being a powerful notation. Powerful notations are key to furthering human intellectual development. You see this repeatedly in many domains, particularly math and physics. New ideas take hundreds of years to figure out become far simpler once someone finds the right notation. Notations grant us the ability to manipulate symbols to develop new ideas. Examples include algebra, zero, and even juggling!\nAPL is a very powerful notation, not just for math but for a range of topics that use similar concepts as math. For example, Aaron Hsu‚Äôs PhD used APL to build a compiler on the GPU.\n\n\nAPL will challenge you to think about programming in new ways\nAPL is an independently developed branch of programming with a rich history. APL as a notation has been developed since the 1960s, largely independently to other branches of programming languages. If you never learn about it, you miss out on an entire branch of languages with an incredibly rich history. Jeremy felt that learning array programming did more for his programming skills than any other language he‚Äôs learned."
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html#setting-up-dyalog-in-jupyter",
    "href": "posts/fastai-array-programming-day-1.html#setting-up-dyalog-in-jupyter",
    "title": "Notes from the fast.ai APL study group",
    "section": "Setting up Dyalog in Jupyter",
    "text": "Setting up Dyalog in Jupyter\n\nInstall Dyalog\nWe‚Äôll use Dyalog, an APL dialect. The first step is to install Dyalog from their download page.\n\n\nInstall the Dyalog Jupyter kernel\nAlthough Dyalog comes with an IDE, we‚Äôll use Jupyter notebooks. Make sure that you‚Äôve installed Jupyter notebook. Then install Dyalog Jupyter kernel following their installation instructions. Although their instructions say that Anaconda is required, I didn‚Äôt need it on MacOS.\n\n\nCreate a notebook with the Dyalog kernel\nClick New, then Dyalog APL.\n\n\n\nCreate a Dyalog notebook in Jupyter by clicking New then Dyalog APL.|Create a Dyalog notebook in Jupyter by clicking New then Dyalog APL.\n\n\nYou should now be able to write Dyalog directly in your notebook! Try it out:\n\n1 2 3 - 4 5 6\n\n¬Ø3 ¬Ø3 ¬Ø3\n\n\n\n\n\nTips for a smoother dev environment\nAPL uses a variety of glyphs like the ¬Ø glyph in the previous output. To make these easier to type in your notebook, you might want to use the APL language bar. It lets you use backtick (`) as a prefix to enter glyphs. For example, &lt;backtick&gt;2 is a shortcut for the ¬Ø glyph. You can type &lt;backtick&gt;&lt;space&gt; to enter a normal backtick again. It also adds a bar to the top of the page with all of the possible glyphs:\n\n\n\nThe APL langauge bar: a horizontal list of APL gylphs.\n\n\nHovering on a glyph shows a its name and keyboard shortucts:\n\n\n\nHovering on the minus sign glyph shows ‚Äònegate minus‚Äô."
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html#a-top-down-learning-plan",
    "href": "posts/fastai-array-programming-day-1.html#a-top-down-learning-plan",
    "title": "Notes from the fast.ai APL study group",
    "section": "A top-down learning plan",
    "text": "A top-down learning plan\nMost tutorials teach APL bottom-up; they go really deep into one topic. FastAI instead strives for top-down teaching. Therefore, we‚Äôll try the approach of learning all of the glyphs first, as simply and quickly as we can. This has the added benefit that the documentation will become useable, since one glyph‚Äôs documentation often contains examples that use other glyphs.\nYou can find a table of all of the gylphs here:\n\n\n\nTables of APL glyphs: primitive functions, and primitive operators, via Dyalog docs.\n\n\nA good way to learn new concepts in APL (and in general) is to look at an example, try to predict what it‚Äôll do before you run it, then run it and compare with your prediction. APL documentation is filled with examples which makes this approach even more powerful. The documentation will often include multiple examples as separate elements of an array.\nFor example, you should read the example for negate:\n\n- 3.2 ¬Ø7 0\n\n¬Ø3.2 7 0\n\n\n\nas three examples:\n\n- 3.2\n\n¬Ø3.2\n\n\n\n\n- ¬Ø7\n\n7\n\n\n\n\n- 0\n\n0\n\n\n\nWe then went on to learn about the following. My notes are sparse at this point - I highly recommend you check out the video instead!\n\nMinus sign; its monadic (negate) and dyadic (minus; subtract) forms.\n\nWe also use operator names when reading APL expressions. For example, ¬Ø2 reads ‚Äúnegate 2‚Äù.\n\nArrays - we needed to know about arrays to understand minus‚Äô examples.\n\nIn APL you create an array (like a vector in math and a tensor in deep learning) by adding spaces between elements.\n\nFunctions; monadic versus dyadic functions.\n\nEach glyph has two forms: monadic and dyadic. This isn‚Äôt the same as ‚Äúmonads‚Äù in Haskell - it simply means a function that takes one argument. In APL you don‚Äôt write functions like f(x,y,z). You either write them as f x if there‚Äôs one argument (monadic), or x f y if there are two (dyadic).\n\nPlus sign; its monadic (conjugate) and dyadic (plus) forms.\nComplex numbers - we needed to know about complex numbers to understand conjugate."
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html#qa",
    "href": "posts/fastai-array-programming-day-1.html#qa",
    "title": "Notes from the fast.ai APL study group",
    "section": "Q&A",
    "text": "Q&A\n\nAre parentheses used for clarifying expressions in APL?\nNot really. Since the precedence rules in APL are so simple, people don‚Äôt tend to use parentheses for clarity, but rather only if they‚Äôre absolutely needed."
  },
  {
    "objectID": "posts/editor.html",
    "href": "posts/editor.html",
    "title": "How to build a text editor with Python and curses",
    "section": "",
    "text": "We‚Äôre going to build a command line text editor from scratch in Python. If you‚Äôd like to learn the most out of this, I‚Äôd recommend to code along. When we encounter problems, I‚Äôll try to state them first before suggesting a solution. I encourage you to pause and give yourself about fifteen minutes to try to solve it first. If you‚Äôre still stuck, move along and compare the solution with your own approach. It‚Äôs also totally fine if you simply read through at your leisure.\nIf you prefer to play around with the final end-to-end solution, check out the accompanying repo.\nOne more thing, if you struggle to even get started, reach out to me on twitter or via email and I‚Äôll try my best to help.\nLet‚Äôs dive right in!"
  },
  {
    "objectID": "posts/editor.html#create-a-curses-application",
    "href": "posts/editor.html#create-a-curses-application",
    "title": "How to build a text editor with Python and curses",
    "section": "Create a curses application",
    "text": "Create a curses application\nWe‚Äôll use the curses library to avoid having to deal with low level issues like efficiently painting to the terminal screen and receiving user input. I‚Äôm going to skim over specifics about curses so we can focus on the editor itself. Please refer to the docs if you‚Äôd like to dig a little deeper.\nStart with a barebones curses application. Create a file, editor.py, and begin with the following:\nimport curses\n\n\ndef main(stdscr):\n    while True:\n        k = stdscr.getkey()\n\n\nif __name__ == \"__main__\":\n    curses.wrapper(main)\ncurses.wrapper prepares your terminal and later restores its original state. It then passes an object that represents the terminal screen, called stdscr (short for standard screen like standard in, out, and error)."
  },
  {
    "objectID": "posts/editor.html#a-way-out",
    "href": "posts/editor.html#a-way-out",
    "title": "How to build a text editor with Python and curses",
    "section": "A way out",
    "text": "A way out\nProblem 1. If you run this, the only way out will be a keyboard interrupt with Ctrl-c. That‚Äôs not great, add a cleaner way out.\nSolution. stdscr.getkey blocks until a key is pressed, then stores it into the k variable, which is mapped to a sys.exit call to cleanly exit the application.\n(Comments like # ... signal that lines from the previous snippet are unchanged. In this case, import curses remains the first line of editor.py, and the if __name__ == \"__main__\": block remains at the end of the file.)\n# ...\nimport sys\n\n\ndef main(stdscr):\n    while True:\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n\n# ...\nRunning the script should land you in a blank page. Then pressing q should get you back out.\n$ python editor.py"
  },
  {
    "objectID": "posts/editor.html#load-and-view-a-file",
    "href": "posts/editor.html#load-and-view-a-file",
    "title": "How to build a text editor with Python and curses",
    "section": "Load and view a file",
    "text": "Load and view a file\nProblem 2. Before we can edit text, we‚Äôll need to be able to display it. Add a way for a user to specify a file. Load that file into memory and display it in the curses window.\nSolution. Add an ArgumentParser that expects a single filename, reads the file‚Äôs contents to a variable. In the main loop, display each row of the file with stdscr.addstr.\nimport argparse\n\n# ...\n\ndef main(stdscr):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"filename\")\n    args = parser.parse_args()\n\n    with open(args.filename) as f:\n        buffer = f.readlines()\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer):\n            stdscr.addstr(row, 0, line)\n\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n\n# ...\nThe contents of the file are stored in-memory until they‚Äôre ready to be rewritten into a file, hence the name buffer. Text editor buffers have some interesting implementations, but we won‚Äôt get into that just yet.\nRerun the application, this time pointing it to a file:\n$ python editor.py editor.py\nThe double editor.py isn‚Äôt a typo. We‚Äôre editing the source of the editor! Which you should now be able to view in your terminal."
  },
  {
    "objectID": "posts/editor.html#view-the-buffer-through-a-window",
    "href": "posts/editor.html#view-the-buffer-through-a-window",
    "title": "How to build a text editor with Python and curses",
    "section": "View the buffer through a window",
    "text": "View the buffer through a window\nProblem 3. Depending on the size of your screen, you may have seen the following error:\n_curses.error: addwstr() returned ERR\nThe application is trying to draw the buffer beyond the length of the screen! In order to fix that, introduce a window with some width and height, and trim the rendered buffer to the width and height of the window.\nSolution. Add a Window class with n_rows and n_cols attributes. In the main function, instantiate a Window with size (curses.LINES - 1, curses.COLS - 1); these are constants that hold the number of lines and columns in the current curses window. Then trim the buffer before rendering it in the main loop.\n(The comment # ... def main(stdscr): hints that the text immediately following it belongs to the main function.)\n# ...\n\nclass Window:\n    def __init__(self, n_rows, n_cols):\n        self.n_rows = n_rows\n        self.n_cols = n_cols\n\n# ... def main(stdscr):\n\n    window = Window(curses.LINES - 1, curses.COLS - 1)\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[:window.n_rows]):\n            stdscr.addstr(row, 0, line[:window.n_cols])\n\n# ..."
  },
  {
    "objectID": "posts/editor.html#move-the-cursor-through-the-buffer",
    "href": "posts/editor.html#move-the-cursor-through-the-buffer",
    "title": "How to build a text editor with Python and curses",
    "section": "Move the cursor through the buffer",
    "text": "Move the cursor through the buffer\nProblem 4. The next step towards editing is cursor movement. Introduce a cursor, positioned at a given row and column. For now, initiate the cursor at (0, 0), then render the stdscr cursor at the current position. Don‚Äôt add any movement functionality just yet.\nSolution. Create a Cursor class with attributes row and col, both default to 0. Instantiate a Cursor in main, and call stdscr.move to the current cursor position in the main loop:\n# ...\n\nclass Cursor:\n    def __init__(self, row=0, col=0):\n        self.row = row\n        self.col = col\n\n# ... def main(stdscr):\n\n    window = Window(curses.LINES - 1, curses.COLS - 1)\n    cursor = Cursor()\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[:window.n_rows]):\n            stdscr.addstr(row, 0, line[:window.n_cols])\n        stdscr.move(cursor.row, cursor.col)\n\n# ...\nThe cursor should now be displayed at (0, 0).\nProblem 5. Next, add cursor movement. Define a method for each direction: up, down, left, and right, each of which update the row or col as required. Then map the arrow keys to these cursor movement methods in the main loop.\nSolution.\n# ... class Cursor:\n\n    def up(self):\n        self.row -= 1\n\n    def down(self):\n        self.row += 1\n\n    def left(self):\n        self.col -= 1\n\n    def right(self):\n        self.col += 1\n\n# ... def main(stdscr):\n\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n        elif k == \"KEY_UP\":\n            cursor.up()\n        elif k == \"KEY_DOWN\":\n            cursor.down()\n        elif k == \"KEY_LEFT\":\n            cursor.left()\n        elif k == \"KEY_RIGHT\":\n            cursor.right()\n\n# ...\nRerun the application and give it a spin. It works great! Until‚Ä¶\nProblem 6. It crashes when you try to move outside of the screen. We should probably restrict the cursor within the buffer.\n(You may have already solved this in your solution to Problem 5. If so, well done, and feel free to skip ahead!)\nSolution. Update the movement methods to only move if they‚Äôll remain within the buffer. Since cursor movement now depends on buffer properties, we also need to pass the buffer through as an argument:\n# ... class Cursor:\n\n    def up(self):\n        if self.row &gt; 0:\n            self.row -= 1\n\n    def down(self, buffer):\n        if self.row &lt; len(buffer) - 1:\n            self.row += 1\n\n    def left(self):\n        if self.col &gt; 0:\n            self.col -= 1\n\n    def right(self, buffer):\n        if self.col &lt; len(buffer[self.row]):\n            self.col += 1\n\n# ... def main(stdscr):\n\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n        elif k == \"KEY_UP\":\n            cursor.up()\n        elif k == \"KEY_DOWN\":\n            cursor.down(buffer)\n        elif k == \"KEY_LEFT\":\n            cursor.left()\n        elif k == \"KEY_RIGHT\":\n            cursor.right(buffer)\n\n# ...\nProblem 7. Almost there. Cursor movement should now mostly work, except that when moving to a shorter line the cursor will float outside the buffer. Fix that.\nSolution. Restrict the cursor‚Äôs col to be within the line we move to:\n# ... class Cursor:\n\n    def up(self, buffer):\n        if self.row &gt; 0:\n            self.row -= 1\n            self._clamp_col(buffer)\n\n    def down(self, buffer):\n        if self.row &lt; len(buffer) - 1:\n            self.row += 1\n            self._clamp_col(buffer)\n\n    def _clamp_col(self, buffer):\n        self.col = min(self.col, len(buffer[self.row]))\n\n# ... def main(stdscr):\n\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n        elif k == \"KEY_UP\":\n            cursor.up(buffer)\n        # ...\n\n# ...\nProblem 8. This works alright, but it‚Äôs not the most convenient. Often when you move to a shorter line and back to the original line, you mean for the cursor to be as it was before you moved at all. Implement this functionality.\nSolution. We can achieve this by introducing a new variable, _col_hint, that keeps track of the last col explicitly moved to, and instead use that to reset the column after line movements.\nWhenever col is set by a horizontal movement, it should also update _col_hint to the same value. That value should be used when clamping. We can use a property and property setter to implement that.\n# ...\n\nclass Cursor:\n    def __init__(self, row=0, col=0, col_hint=None):\n        self.row = row\n        self._col = col\n        self._col_hint = col if col_hint is None else col_hint\n\n    @property\n    def col(self):\n        return self._col\n\n    @col.setter\n    def col(self, col):\n        self._col = col\n        self._col_hint = col\n\n    # ...\n\n    def _clamp_col(self, buffer):\n        self._col = min(self._col_hint, len(buffer[self.row]))\n\n# ...\nNote that _clamp_col sets the internal variable _col directly, avoiding the setter thus not resetting _col_hint.\nProblem 9. There‚Äôs one final addition that should also improve the user experience. If the cursor is moved horizontally outside the buffer, wrap to the start (or end) of the next (or previous) line.\nSolution.\n# ... class Cursor:\n\n    def left(self, buffer):\n        if self.col &gt; 0:\n            self.col -= 1\n        elif self.row &gt; 0:\n            self.row -= 1\n            self.col = len(buffer[self.row])\n\n    def right(self, buffer):\n        if self.col &lt; len(buffer[self.row]):\n            self.col += 1\n        elif self.row &lt; len(buffer) - 1:\n            self.row += 1\n            self.col = 0\n\n# ... def main(stdscr):\n\n        elif k == \"KEY_LEFT\":\n            cursor.left(buffer)\n\n# ...\nGive it a spin. All should work well except when the cursor moves outside of the window."
  },
  {
    "objectID": "posts/editor.html#scroll-the-window-to-the-cursor",
    "href": "posts/editor.html#scroll-the-window-to-the-cursor",
    "title": "How to build a text editor with Python and curses",
    "section": "Scroll the window to the cursor",
    "text": "Scroll the window to the cursor\nProblem 10. We currently have no way of seeing any part of the buffer that‚Äôs outside the window. Worse still, we can also move the cursor outside of the window! Scroll the window vertically as the cursor moves. Don‚Äôt worry about horizontal scrolling for now.\nSolution. Add row and col attributes to the Window that track the current position of the window as it scrolls through the buffer (specifically, the position of the top-left of the window). Then add methods to scroll the window vertically.\nHaving learned from cursor movement, we‚Äôll be sure to do the necessary checks the first time round: only scroll up if we‚Äôre not already at the top of the buffer and if the cursor exceeds the top of the window, and similarly for downward scrolling. In the main loop, scroll the window after moving the cursor. And finally, update where we start slicing the buffer when rendering.\n# ...\n\nclass Window:\n\n    def __init__(self, n_rows, n_cols, row=0, col=0):\n        self.n_rows = n_rows\n        self.n_cols = n_cols\n        self.row = row\n        self.col = col\n\n    @property\n    def bottom(self):\n        return self.row + self.n_rows - 1\n\n    def up(self, cursor):\n        if cursor.row == self.row - 1 and self.row &gt; 0:\n            self.row -= 1\n\n    def down(self, buffer, cursor):\n        if cursor.row == self.bottom + 1 and self.bottom &lt; len(buffer) - 1:\n            self.row += 1\n\n# ... def main(stdscr):\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[window.row:window.row + window.n_rows]):\n            stdscr.addstr(row, 0, line)\n        stdscr.move(cursor.row, cursor.col)\n\n# ...\n        elif k == \"KEY_UP\":\n            cursor.up()\n            window.up(cursor)\n        elif k == \"KEY_DOWN\":\n            cursor.down(buffer)\n            window.down(buffer, cursor)\n        elif k == \"KEY_LEFT\":\n            cursor.left()\n            window.up(cursor)\n        elif k == \"KEY_RIGHT\":\n            cursor.right(buffer)\n            window.down(buffer, cursor)\n# ...\nNote that left and right movement may require vertical scrolling since the cursor may be wrapped to the previous or next line.\nThe last crucial piece is to translate the cursor‚Äôs actual position, which is in terms of the buffer, to be in terms of what‚Äôs displayed: the window. Add a translate method to the window, and use it to render the cursor:\n# ... class Window:\n\n    def translate(self, cursor):\n        return cursor.row - self.row, cursor.col - self.col\n\n# ... def main(stdscr):\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[window.row:window.row + window.n_rows]):\n            stdscr.addstr(row, 0, line)\n        stdscr.move(*window.translate(cursor))\n\n# ...\nProblem 11. We‚Äôve addressed vertical scrolling, but long lines still present an issue. There are two ways we might address long lines. We could either scroll the entire window with the cursor, as we did for vertical scrolling. This is how most editors work. Or we could scroll only the selected line to follow the cursor, which as far as I know is only implemented by nano. Let‚Äôs implement the second approach.\nThe desired behaviour is that when the cursor exceeds some margin away from the right edge of the window, the window should be moved one page to the right, and similarly for the left side.\nSolution. Add a horizontal_scroll method to Window that implements this, and call it after any cursor movements in the main loop.\n# ... class Window:\n\n    def horizontal_scroll(self, cursor, left_margin=5, right_margin=2):\n        n_pages = cursor.col // (self.n_cols - right_margin)\n        self.col = max(n_pages * self.n_cols - right_margin - left_margin, 0)\n\n# ... def main(stdscr):\n\n        elif k == \"KEY_UP\":\n            cursor.up()\n            window.up(cursor)\n            window.horizontal_scroll(cursor)\n        elif k == \"KEY_DOWN\":\n            cursor.down(buffer)\n            window.down(buffer, cursor)\n            window.horizontal_scroll(cursor)\n        elif k == \"KEY_LEFT\":\n            cursor.left()\n            window.up(cursor)\n            window.horizontal_scroll(cursor)\n        elif k == \"KEY_RIGHT\":\n            cursor.right(buffer)\n            window.down(buffer, cursor)\n            window.horizontal_scroll(cursor)\n\n# ...\nNext, update how the buffer renders long lines by including characters that indicate that a given line has more content on the left (¬´) or right (¬ª).\n# ... def main(stdscr):\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[window.row:window.row + window.n_rows]):\n            if row == cursor.row - window.row and window.col &gt; 0:\n                line = \"¬´\" + line[window.col + 1:]\n            if len(line) &gt; window.n_cols:\n                line = line[:window.n_cols - 1] + \"¬ª\"\n            stdscr.addstr(row, 0, line)\n        stdscr.move(*window.translate(cursor))\n\n    # ..."
  },
  {
    "objectID": "posts/editor.html#edit-the-buffer",
    "href": "posts/editor.html#edit-the-buffer",
    "title": "How to build a text editor with Python and curses",
    "section": "Edit the buffer",
    "text": "Edit the buffer\nAnd now to the key ingredient, actually editing text!\nStart by adding a Buffer class that wraps the list of lines. Implement __len__ and __getitem__ so that any dependents of buffer needn‚Äôt change. Set buffer to a Buffer instance instead of the current list of lines.\n# ...\n\nclass Buffer:\n    def __init__(self, lines):\n        self.lines = lines\n\n    def __len__(self):\n        return len(self.lines)\n\n    def __getitem__(self, index):\n        return self.lines[index]\n\n# ... def main(stdscr):\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"filename\")\n    args = parser.parse_args()\n\n    with open(args.filename) as f:\n        buffer = Buffer(f.read().splitlines())\n\n# ...\nNow‚Äôs a good time for a tiny refactor: extract len(buffer) - 1 to the Buffer.bottom property. You might argue that this isn‚Äôt worth being extracted. My reasoning is that the last column in a line is len(buffer[row]) whereas the last row in a buffer is len(buffer) - 1, and I can never get it right the first time!\nI think it‚Äôs good to be aware of the kinds of bugs you tend to introduce, rather than to always follow a dogmatic approach. It also has a nice symmetry with Window.bottom, though that‚Äôs less important. It might be worth considering doing similar for len(buffer[row]), but I find that easy to remember and already concise.\n# ... class Buffer:\n\n    @property\n    def bottom(self):\n        return len(self) - 1\n\n# ... class Cursor:\n\n    def down(self, buffer):\n        if self.row &lt; buffer.bottom:\n            self.row += 1\n            self._clamp_col(buffer)\n\n    # ...\n\n    def right(self, buffer):\n        if self.col &lt; len(buffer[self.row]):\n            self.col += 1\n        elif self.row &lt; buffer.bottom:\n            self.row += 1\n            self.col = 0\n\n# ... class Window:\n\n    def down(self, buffer, cursor):\n        if cursor.row == self.bottom + 1 and self.bottom &lt; buffer.bottom:\n            self.row += 1\n\n# ...\nWe‚Äôll be adding three methods to the buffer: insert, split, and delete.\n\nInsert a string into the buffer\nProblem 12. If an unmapped key is pressed, insert it into the buffer at the current cursor position.\nSolution.\nSince the buffer stores text as a list of lines, and the cursor moves through a two-dimensional space, there‚Äôs a tiny bit of work we need to do to insert text at a given cursor.\nPop the line under the cursor, split it at the cursor, and concatenate the before part, the string to be inserted, and the after part. Insert the concatenated string into the buffer at the cursor. And as usual, call the method in the main loop. This case differs slightly from previous, in that we‚Äôll map all unmapped keys to Buffer.insert. That‚Äôs probably not ideal, for example, a user might enter Ctrl-i which will write ^I to the buffer, but it‚Äôll do for now.\n# ... class Buffer:\n\n    def insert(self, cursor, string):\n        row, col = cursor.row, cursor.col\n        current = self.lines.pop(row)\n        new = current[:col] + string + current[col:]\n        self.lines.insert(row, new)\n\n# ... def main(stdscr):\n\n    if k == \"q\":\n        sys.exit(0)\n    # ...\n    else:\n        buffer.insert(cursor, k)\n\n# ...\nTest it out. It‚Äôll insert text, but won‚Äôt move the cursor after the inserted text. All we need to do is move right for each inserted character. Since we already have a command to move the cursor right (and scroll the window as needed), now‚Äôs the time to extract a right function and re-use it:\n# ...\n\ndef right(window, buffer, cursor):\n    cursor.right(buffer)\n    window.down(buffer, cursor)\n    window.horizontal_scroll(cursor)\n\n# ... def main(stdscr):\n\n    elif k == \"KEY_RIGHT\":\n        right(window, buffer, cursor)\n    # ...\n    else:\n        buffer.insert(cursor, k)\n        for _ in k:\n            right(window, buffer, cursor)\n\n# ...\n\n\nSplit a line in the buffer\nProbem 12. If you hit enter, you won‚Äôt get the expected result, which is to split the line at the cursor.\nSolution. Implement split as below, similar to insert.\n# ... class Buffer:\n\n    def split(self, cursor):\n        row, col = cursor.row, cursor.col\n        current = self.lines.pop(row)\n        self.lines.insert(row, current[:col])\n        self.lines.insert(row + 1, current[col:])\n\n# ... def main(stdscr):\n\n    elif k == \"\\n\":\n        buffer.split(cursor)\n        right(window, buffer, cursor)\n\n# ...\n\n\nDelete a character from the buffer\nProblem 13. As in the previous section, hitting delete or backspace won‚Äôt give the expected result. Start by implementing a delete command, bound to the delete key, that deletes the character under the cursor.\nSolution. Add a delete method. If the cursor is at the last position in the buffer, don‚Äôt do anything. Otherwise, there are two options. Either the cursor is inside a line, then follow similar logic to insert but instead of adding a string remove a character. Or the cursor is at the end of the line, then join the current line to the next.\n# ... class Buffer:\n\n    def delete(self, cursor):\n        row, col = cursor.row, cursor.col\n        if (row, col) &lt; (self.bottom, len(self[row])):\n            current = self.lines.pop(row)\n            if col &lt; len(self[row]):\n                new = current[:col] + current[col + 1:]\n                self.lines.insert(row, new)\n            else:\n                next = self.lines.pop(row)\n                new = current + next\n                self.lines.insert(row, new)\n\n# ... def main(stdscr):\n\n    elif k in (\"KEY_DELETE\", \"\\x04\"):\n        buffer.delete(cursor)\n\n# ...\nOn MacOS, curses doesn‚Äôt correctly decode the backspace and delete keys, they‚Äôre instead returned as \\x7f and \\x04 respectively. I haven‚Äôt found a satisfactory answer for why this is the case. If you know, I‚Äôd love to hear!\nProblem 14. Implement backspace.\nSolution. Backspace can be implemented by moving left and then deleting. Just as we extracted a right function for insertion, we‚Äôll extract a left function here:\n# ...\n\ndef left(window, buffer, cursor):\n    cursor.left(buffer)\n    window.up(cursor)\n    window.horizontal_scroll(cursor)\n\n# ... def main(stdscr):\n\n    elif k in (\"KEY_BACKSPACE\", \"\\x7f\"):\n        if (cursor.row, cursor.col) &gt; (0, 0):\n            left(window, buffer, cursor)\n            buffer.delete(cursor)\n\n# ...\nAnd look at that! You‚Äôve built a minimal yet functional text editor.\nProblem 15. There‚Äôs one key piece of functionality still missing: saving the edited file. I‚Äôll leave that as the final unsolved problem."
  },
  {
    "objectID": "posts/editor.html#what-next",
    "href": "posts/editor.html#what-next",
    "title": "How to build a text editor with Python and curses",
    "section": "What next?",
    "text": "What next?\nI hope you enjoyed working through this, and that you learned something new. If you did or if you have any other questions or comments, feel free to reach out to me on twitter or via email.\nIf this whet your appetite and you‚Äôre looking for more, here are some exercises you might find interesting, in roughly increasing difficulty:\n\nRemap cursor movement to Ctrl-p (up), Ctrl-n (down), Ctrl-b (left), and Ctrl-f (right).\nAdd page up and page down commands.\nAdd a command to save the buffer to a file.\nRewrite horizontal scrolling to move the entire window rather than only the current line.\nAdd a status line to the bottom of the window that displays the name of the file being edited and the current cursor position.\nAdd commands to move one word left or right.\nIf the buffer is modified and not yet saved, print a message in the status line and don‚Äôt let the user exit. Add a force exit command as well.\nRewrite the application so that there‚Äôs no mutable state. I‚Äôve found dataclasses with the dataclass.replace function a convenient way to write applications around immutable objects."
  },
  {
    "objectID": "posts/editor.html#credits",
    "href": "posts/editor.html#credits",
    "title": "How to build a text editor with Python and curses",
    "section": "Credits",
    "text": "Credits\nMany thanks to the following people and projects for sharing their great work, upon which a lot of this was based!\n\nMany thanks to Pavel Spirhanzl and Alexandre Pajak for their keen eyes in identifying bugs in early versions.\nGary Bernhardt‚Äôs Text Editor From Scratch screencast.\nAnthony Sottile‚Äôs babi.\nnano source.\nEmacs source. In my opinion, the best way to explore the source is through Emacs‚Äô built-in help commands."
  }
]